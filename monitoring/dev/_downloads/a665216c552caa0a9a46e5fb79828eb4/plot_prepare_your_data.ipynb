{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Preparing Your Tabular Data for Deepchecks Monitoring\n\n## What You Need to Get Through the Tutorial\nThe in order to start monitoring your tabular data and model using Deepchecks you will need to have the following\npre-requisites:\n\n* Data which can be loaded into a pandas DataFrame. This can be a csv file, a database connection or any other.\n* A timestamp column in your data. This column will be used to identify the time of the sample and will be used to\n  monitor the data over time. In most cases, the time of the model prediction will be a good choice.\n* A working python environment with deepchecks and deepchecks-client installed. See\n  :doc:`quickstart guide </user-guide/tabular/auto_quickstarts/plot_quickstart>` for additional details.\n\nAll the pre-requisites are fulfilled? Great! Let's get started.\n\n## Preparing Your Data\nIn this short tutorial we'll go over the required steps in order to prepare your data\nfor Deepchecks Monitoring which include:\n\n1. `Preparing the Reference Data <prepare_your_tabular_data__reference_data>` (Optional)\n2. `Creating a Data Schema <prepare_your_tabular_data__data_schema>`\n3. `Preparing the Production Data <prepare_your_tabular_data__production_data>`\n4. `Supplying Model Predictions <prepare_your_tabular_data__model_predictions>` (Optional)\n\nAfter this tutorial you will have a ready to go setup in order to start monitoring your data and model using\nDeepchecks. See :doc:`Setup Guide </user-guide/tabular/tabular_setup>` for a follow-up tutorial on\nsetting up your monitoring system.\n\nIn this tutorial we will use the [Lending Club loan data](https://www.kaggle.com/datasets/wordsforthewise/lending-club)_ which is stored in two csv files, one containing the\ndata used for the model training (reference data) and the other containing the production data. It is preferable to run\nthis tutorial on your own data or one that you are familiar with.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preparing the Reference Data (Optional)\n---------------------------------------\n\nReference data represent the data used for model training and is required in order to run checks which compare\nthe production data to the reference data. An example of such a check is the\n:doc:`Feature Drift <deepchecks:checks_gallery/tabular/train_test_validation/plot_train_test_feature_drift>` check.\n\nWe will load the reference data from a csv file and use it to create a\n`Dataset <deepchecks:tabular__dataset_object>` object which is used in order to create the\ndata schema and upload the reference data to the monitoring system.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\ntrain_df = pd.read_csv('https://figshare.com/ndownloader/files/39316160')\ntrain_df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So what do we have? Let's note the special columns in our data:\n\n1. issue_d - The timestamp of the sample (This is unnecessary for reference data, but is required for production data)\n2. id - the id of the loan application\n3. loan_status - Our label, which is the final status of the loan. 0 means \"paid in full\", and 1 are defaults.\n\nAll the other columns are features that can be used by our model to predict whether the user will default or not.\n\nIn order to create a Dataset object we must specify the name of the label column and which features are categorical.\nIf the data contains a datetime column, index column or other columns which are not features, we need to also pass\na features argument containing the features column names.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular import Dataset\n\nfeatures = train_df.columns.drop(['id', 'issue_d', 'loan_status'])\ncat_features = ['sub_grade', 'home_ownership', 'term', 'purpose', 'application_type', 'verification_status',\n                'addr_state', 'initial_list_status']\nref_dataset = Dataset(train_df, cat_features=cat_features, features=features, label='loan_status')\nref_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n### Creating the Data Schema\nSchema file contains the description of the data (features and additional data) associated with a model version and\nis used by the monitoring system to validate the production data.\n**It is highly recommended to review the created schema file before moving forward to creating the model version.**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks_client import create_schema, read_schema\n\nschema_file_path = 'schema_file.yaml'\ncreate_schema(dataset=ref_dataset, schema_output_file=schema_file_path)\nread_schema(schema_file_path)\n# Note: for conveniently changing the auto-inferred schema it's recommended to edit the textual file with an\n# app of your choice.\n# After editing, you can use the `read_schema` function to verify the validity of the syntax in your updated schema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n### Preparing the Production Data\n\nIn order to prepare the production data we will take a closer look at index and datetime columns which are\nrequired for production data but not for reference data.\n\nThe index is the global identifier for a sample in the deepchecks system and is used in various displays\nas well as for future updates of the sample as well. It is crucial to provide meaningful values for this column.\nIn our case we will use the id column as the index.\n\nThe timestamps represent either the time the sample was observed or the time the model prediction took place.\nIt should be provided in Unix timestamp format (seconds since 1970-01-01 00:00:00 UTC). In our case we will use\nthe issue_d column and convert it to the required format.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from time import time\n\nprod_data = pd.read_csv('https://figshare.com/ndownloader/files/39316157', parse_dates=['issue_d'])\n# Convert pandas datetime format to unix timestamp\nprod_data['issue_d'] = prod_data['issue_d'].astype(int) // 10 ** 9\n# we will varify that the index column is unique and that the datetime column is in the correct format\nassert prod_data.index.is_unique\nassert prod_data['issue_d'].min() > 0 and prod_data['issue_d'].max() < int(time())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n### Supplying Model Predictions\n\nIf we wish to also monitor the model's behaviour we need to provide the model's predictions for both\nthe reference and production data in the required format and optionally also the model feature importance.\n\nCurrently, model predictions are only supported for regression and classification tasks. For classification tasks,\nit is preferable to provide the predicted probabilities per class rather than the predicted classes themselves.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Loading the model (CatBoost Classifier)\nimport joblib\nfrom urllib.request import urlopen\n\nwith urlopen('https://figshare.com/ndownloader/files/39316172') as f:\n    model = joblib.load(f)\n\n# Extracting feature importance - optional\nfeature_importance = pd.Series(model.feature_importances_ / sum(model.feature_importances_), index=model.feature_names_)\n\n# Predicting on the reference data and production data\nref_predictions = model.predict_proba(train_df[features].fillna('NONE'))\nprod_predictions = model.predict_proba(prod_data[features].fillna('NONE'))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}