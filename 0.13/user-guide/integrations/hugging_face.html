
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
        w[l] = w[l] || []; w[l].push({
            'gtm.start':
                new Date().getTime(), event: 'gtm.js'
        }); var f = d.getElementsByTagName(s)[0],
            j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
                'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-NNKXRJQ');</script>
<!-- End Google Tag Manager -->
<meta name="title" content="HuggingFace Transformers | Deepchecks Documentation">
<meta name="description" content="Do you need to know more about HuggingFace Transformers? Read more at Deepchecks Online Documentation">
<meta name="docsearch:version" content="0.1">


<!-- Warning: 
        The 'shortcut link' type is often seen before icon, but this link type is non-conforming, 
        ignored and web authors must not use it anymore. 
        MDN docs https://developer.mozilla.org/en-US/docs/Web/HTML/Link_types
    -->
<link rel="shortcut icon" href="/_static/favicons/favicon.ico">
<link rel="canonical" href="https://docs.deepchecks.com/stable/user-guide/integrations/hugging_face.html" />

<link rel="icon" href="/_static/favicons/favicon.png" sizes="32x32">
<link rel="icon" href="/_static/favicons/favicon.png" sizes="192x192">

<!-- Note: 
        Apple's iOS does not use this 'link' type, nor the 'sizes' attribute, 
        like others mobile browsers do, to select a webpage icon for Web Clip 
        or a start-up placeholder. Instead it uses the non-standard 'apple-touch-icon'.
        MDN docs: https://developer.mozilla.org/en-US/docs/Web/HTML/Link_types;
        Safari Web Content Guide: https://developer.apple.com/library/archive/documentation/AppleApplications/Reference/SafariWebContent/ConfiguringWebApplications/ConfiguringWebApplications.html#//apple_ref/doc/uid/TP40002051-CH3-SW4
    -->
<link rel="apple-touch-icon" href="/_static/favicons/apple-touch-icon.png" sizes="32x32">
<link rel="apple-touch-icon" href="/_static/favicons/apple-touch-icon.png" sizes="192x192">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@docsearch/css@3" />


    <title>HuggingFace Transformers &#8212; Deepchecks Documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/rtd_sphinx_search.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" crossorigin="anonymous"></script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"
    crossorigin="anonymous"></script>

    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Airflow" href="airflow.html" />
    <link rel="prev" title="H2O" href="h2o.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>

<body data-spy="scroll" data-target="#bd-toc-nav">
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NNKXRJQ" height="0" width="0"
            style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
    <script>
        require.config({
            paths: {
                "docsearchLib": "https://cdn.jsdelivr.net/npm/@docsearch/js@3?noext",
                "clipboardjs": "/0.1/_static/clipboard.min"
            }
        }

        );
        require(["docsearchLib"], function (docsearch) {
            docsearch({
                appId: "3UQ0BSGJ1N", apiKey: "83d250f88e29e9906a50ddf40a1871ce", indexName: "deepchecks", container: '#algolia-search', debug: false,
                searchParameters: {
                    facetFilters: ["version:0.1"]
                }
            });
        });
        require(["clipboardjs"], function(clipboardJS) {
            window.ClipboardJS=clipboardJS
        });
    </script>
    <div style="display:none;" id="dc-submodule">general</div>
    <script data-url_root="/" id="documentation_options" src="/0.1/_static/documentation_options.js"></script>
    <script src="/0.1/_static/copybutton.js"></script>

    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/deepchecks_logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../getting-started/index.html">
  Getting Started
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../index.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../checks_gallery/tabular.html">
  Tabular Checks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../checks_gallery/vision.html">
  Vision Checks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../api/index.html">
  API Reference
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-primary btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        0.1  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<!-- NOTE: this JS must live here (not in our global JS file) because it relies
     on being processed by Jinja before it is run (specifically for replacing
     variables user-guide/integrations/hugging_face and {'json_url': 'https://docs.deepchecks.com/dev/_static/switcher.json', 'version_match': '0.1', 'url_template': 'https://docs.deepchecks.com/{version}/'}.
-->

<script type="text/javascript">
// Check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "user-guide/integrations/hugging_face.html",
          tryUrl = event.target.getAttribute("href");
    let otherDocsHomepage = tryUrl.replace(currentFilePath, "");
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    // this prevents the browser from following the href of the clicked node
    // (which is fine because this function takes care of redirecting)
    return false;
}

// Populate the version switcher from the JSON config file
(function () {
    $.getJSON("https://docs.deepchecks.com/dev/_static/switcher.json", function(data, textStatus, jqXHR) {
        const currentFilePath = "user-guide/integrations/hugging_face.html";
        // create links to the corresponding page in the other docs versions
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // create the node
            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.textContent = `${entry.name}`;
            node.setAttribute("href", `${entry.url}${currentFilePath}`);
            // on click, AJAX calls will check if the linked page exists before
            // trying to redirect, and if not, will redirect to the homepage
            // for that version of the docs.
            node.onclick = checkPageExistsAndRedirect;
            // Add dataset values for the version and name in case people want
            // to apply CSS styling based on this information.
            node.dataset["versionName"] = entry.name;
            node.dataset["version"] = entry.version;

            $("#version_switcher_menu").append(node);
            // replace dropdown button text with the preferred display name of
            // this version, rather than using sphinx's 0.1 variable.
            // also highlight the dropdown entry for the currently-viewed
            // version's entry
            if (entry.version == "0.1") {
                node.classList.add("active");
                let btn = document.getElementById("version_switcher_button");
                btn.innerText = btn.dataset["activeVersionName"] = entry.name;
                btn.dataset["activeVersion"] = entry.version;
            }
        });
    });
})();
</script>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Quick Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/deepchecks/deepchecks" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://deepcheckscommunity.slack.com/join/shared_invite/zt-y28sjt1v-PBT50S3uoyWui_Deg5L_jg#/shared-invite/email" rel="noopener" target="_blank" title="Slack"><span><i class="fab fa-slack"></i></span>
            <label class="sr-only">Slack</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://pypi.org/project/deepchecks/" rel="noopener" target="_blank" title="PyPI"><span><i class="fab fa-python"></i></span>
            <label class="sr-only">PyPI</label></a>
        </li>
      </ul>
      </div>
      
      <div class="navbar-end-item">
        <div id="topright-dropdown-menu" class="dropdown" style="width: fit-content;">
    <a 
        class="btn dropdown-toggle" 
        id="topright-dropdown-menu-link" 
        data-toggle="dropdown" 
        aria-haspopup="true" 
        aria-expanded="false"
        data-offset="-100,10">
            <i class="fas fa-bars"></i>
    </a>
    <div class="dropdown-menu" aria-labelledby="topright-dropdown-menu-link" x-placement="bottom-start">
        <a class="dropdown-item" href="https://github.com/deepchecks/deepchecks/issues/new?title=[Docs] Documentation contains a mistake.&body=Package Version: 0.1;
Page: user-guide/integrations/hugging_face&labels=labels=chore/documentation" target="_blank" rel="noopener noreferrer">
            <i class="fas fa-pencil-alt"></i> Report a problem
        </a>
        
            <a 
                
                    href="/0.1/_sources/user-guide/integrations/hugging_face.rst.txt"
                
                
                class="dropdown-item" 
                target="_blank" 
                rel="noopener noreferrer">
                <i class="fas fa-code"></i> Show Source
            </a>
        
    </div>
</div>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><div id="algolia-search">
<!-- <form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form> -->
</div><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  General
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../general/when_should_you_use.html">
   When Should You Validate &amp; Built-In Suites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../general/deepchecks_hierarchy.html">
   Deepchecks Hierarchy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../general/showing_results.html">
   Viewing Deepchecks Results
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../general/export_save_results.html">
   Exporting Deepchecks’ Results
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../general/customizations/examples/index.html">
   Customizations
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../general/customizations/examples/plot_create_a_custom_check.html">
     Create a Custom Check
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../general/customizations/examples/plot_configure_check_conditions.html">
     Configure Check Conditions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../general/customizations/examples/plot_create_a_custom_suite.html">
     Create a Custom Suite
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../general/metrics_guide.html">
   Metrics Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../general/drift_guide.html">
   Drift User Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../general/ci_cd.html">
   Using Deepchecks In CI/CD
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tabular
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../tabular/auto_quickstarts/index.html">
   Tabular Quickstarts
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../tabular/auto_quickstarts/plot_quickstart_in_5_minutes.html">
     Full Suite Quickstart
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tabular/auto_quickstarts/plot_quick_model_evaluation.html">
     Model Evaluation Suite Quickstart
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tabular/auto_quickstarts/plot_quick_data_integrity.html">
     Data Integrity Suite Quickstart
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tabular/auto_quickstarts/plot_quick_train_test_validation.html">
     Train-Test Validation Suite Quickstart
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../tabular/auto_tutorials/index.html">
   Tabular Tutorials
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../tabular/auto_tutorials/plot_add_a_custom_check.html">
     Creating a Custom Check
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tabular/auto_tutorials/plot_phishing_urls.html">
     Use Cases - Classifying Malicious URLs
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tabular/dataset_object.html">
   The Dataset Object
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tabular/supported_models.html">
   Working with Models and Predictions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tabular/feature_importance.html">
   Feature Importance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tabular/custom_check_templates.html">
   Custom Check Templates
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Vision
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../vision/auto_tutorials/index.html">
   Computer Vision Tutorials
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../vision/auto_tutorials/plot_simple_classification_tutorial.html">
     Image Data Validation in 5 Minutes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../vision/auto_tutorials/plot_segmentation_tutorial.html">
     Semantic Segmentation Tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../vision/auto_tutorials/plot_classification_tutorial.html">
     Image Classification Tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../vision/auto_tutorials/plot_custom_task_tutorial.html">
     Custom Task Tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../vision/auto_tutorials/plot_detection_tutorial.html">
     Object Detection Tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../vision/auto_tutorials/plot_custom_checks.html">
     Creating a Custom Check
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../vision/VisionData.html">
   The Vision Data Class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../vision/supported_tasks_and_formats.html">
   Supported Tasks and Formats
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../vision/vision_properties.html">
   Vision Properties
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../vision/custom_check_templates.html">
   Custom Check Templates
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  NLP
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../nlp/auto_quickstarts/index.html">
   NLP Quickstarts
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../nlp/auto_quickstarts/plot_text_classification.html">
     Test NLP Classification Tasks - Quickstart
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../nlp/supported_tasks.html">
   Supported Tasks and Formats
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Integrations
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="spark_databricks.html">
   Spark &amp; Databricks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="pytest.html">
   Pytest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="h2o.html">
   H2O
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   HuggingFace Transformers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="airflow.html">
   Airflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cml.html">
   CML
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="junit.html">
   JUnit
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../general/exporting_results/examples/plot_exports_output_to_wandb.html">
   Weights &amp; Biases (wandb)
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#building-a-visiondata-object-for-the-detr-model">
   Building a VisionData Object for the DETR Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-pre-made-yolov5s">
   Load Pre-Made YOLOv5s
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#benchmarking-yolov5s-against-detr-resnet">
   Benchmarking YOLOv5s Against DETR ResNet
  </a>
 </li>
</ul>

</nav>
              </div>
              
            
          </div>
          

          
    
        
    
    <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
        
        
            <div>
                
  <section id="huggingface-transformers">
<h1>HuggingFace Transformers<a class="headerlink" href="#huggingface-transformers" title="Permalink to this headline">#</a></h1>
<p>This tutorial demonstrates how deepchecks.vision can be used on a Hugging Face transformer model. We will use deepchecks
to compare the performance of the <a class="reference external" href="https://huggingface.co/facebook/detr-resnet-50">DETR ResNet</a> transformers model
against the widely used <a class="reference external" href="https://arxiv.org/abs/1804.02767">YOLOv5s</a> model on the <a class="reference external" href="https://cocodataset.org/">COCO</a>
dataset.</p>
<section id="building-a-visiondata-object-for-the-detr-model">
<h2>Building a VisionData Object for the DETR Model<a class="headerlink" href="#building-a-visiondata-object-for-the-detr-model" title="Permalink to this headline">#</a></h2>
<p>In order to use the DETR model, we need to translate the image, label and prediction formats to the ones supported by
deepchecks (see the <a class="reference internal" href="../vision/supported_tasks_and_formats.html"><span class="doc">Format Guide</span></a>) and define a
<a class="reference internal" href="../../api/generated/deepchecks.vision.vision_data.VisionData.html#deepchecks.vision.vision_data.VisionData" title="deepchecks.vision.vision_data.VisionData"><code class="xref py py-class docutils literal notranslate"><span class="pre">deepchecks.vision.vision_data.VisionData</span></code></a> object that will be used to run the checks.</p>
<p>We’ll start by loading the DETR ResNet model from the Hugging Face Transformers library:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DetrForObjectDetection</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">detr_resnet</span> <span class="o">=</span> <span class="n">DetrForObjectDetection</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;facebook/detr-resnet-50&#39;</span><span class="p">)</span>
<span class="n">detr_resnet</span> <span class="o">=</span> <span class="n">detr_resnet</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">detr_resnet</span> <span class="o">=</span> <span class="n">detr_resnet</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

</pre></div>
</div>
<p>And then we’ll move on to implementing the COCODETRData class, which will help us keep all the required format
conversions in one place.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Iterable</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">deepchecks.vision</span> <span class="kn">import</span> <span class="n">VisionData</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">T</span>


<span class="k">class</span> <span class="nc">COCODETRData</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Class for loading the COCO dataset meant for the DETR ResNet50 model`.</span>

<span class="sd">    Implement the necessary methods to load the images, labels and generate model predictions in a format comprehensible</span>
<span class="sd">     by deepchecks.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># This is the list of classes returned by the DETR model. Stored in order to convert to the same class order as the</span>
    <span class="c1"># COCO dataset used by the YOLOv5s model.</span>
    <span class="n">DETR_CLASSES</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;person&#39;</span><span class="p">,</span> <span class="s1">&#39;bicycle&#39;</span><span class="p">,</span> <span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="s1">&#39;motorcycle&#39;</span><span class="p">,</span> <span class="s1">&#39;airplane&#39;</span><span class="p">,</span> <span class="s1">&#39;bus&#39;</span><span class="p">,</span>
        <span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;truck&#39;</span><span class="p">,</span> <span class="s1">&#39;boat&#39;</span><span class="p">,</span> <span class="s1">&#39;traffic light&#39;</span><span class="p">,</span> <span class="s1">&#39;fire hydrant&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span>
        <span class="s1">&#39;stop sign&#39;</span><span class="p">,</span> <span class="s1">&#39;parking meter&#39;</span><span class="p">,</span> <span class="s1">&#39;bench&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">,</span>
        <span class="s1">&#39;sheep&#39;</span><span class="p">,</span> <span class="s1">&#39;cow&#39;</span><span class="p">,</span> <span class="s1">&#39;elephant&#39;</span><span class="p">,</span> <span class="s1">&#39;bear&#39;</span><span class="p">,</span> <span class="s1">&#39;zebra&#39;</span><span class="p">,</span> <span class="s1">&#39;giraffe&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;backpack&#39;</span><span class="p">,</span>
        <span class="s1">&#39;umbrella&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;handbag&#39;</span><span class="p">,</span> <span class="s1">&#39;tie&#39;</span><span class="p">,</span> <span class="s1">&#39;suitcase&#39;</span><span class="p">,</span> <span class="s1">&#39;frisbee&#39;</span><span class="p">,</span> <span class="s1">&#39;skis&#39;</span><span class="p">,</span>
        <span class="s1">&#39;snowboard&#39;</span><span class="p">,</span> <span class="s1">&#39;sports ball&#39;</span><span class="p">,</span> <span class="s1">&#39;kite&#39;</span><span class="p">,</span> <span class="s1">&#39;baseball bat&#39;</span><span class="p">,</span> <span class="s1">&#39;baseball glove&#39;</span><span class="p">,</span>
        <span class="s1">&#39;skateboard&#39;</span><span class="p">,</span> <span class="s1">&#39;surfboard&#39;</span><span class="p">,</span> <span class="s1">&#39;tennis racket&#39;</span><span class="p">,</span> <span class="s1">&#39;bottle&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;wine glass&#39;</span><span class="p">,</span>
        <span class="s1">&#39;cup&#39;</span><span class="p">,</span> <span class="s1">&#39;fork&#39;</span><span class="p">,</span> <span class="s1">&#39;knife&#39;</span><span class="p">,</span> <span class="s1">&#39;spoon&#39;</span><span class="p">,</span> <span class="s1">&#39;bowl&#39;</span><span class="p">,</span> <span class="s1">&#39;banana&#39;</span><span class="p">,</span> <span class="s1">&#39;apple&#39;</span><span class="p">,</span> <span class="s1">&#39;sandwich&#39;</span><span class="p">,</span>
        <span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="s1">&#39;broccoli&#39;</span><span class="p">,</span> <span class="s1">&#39;carrot&#39;</span><span class="p">,</span> <span class="s1">&#39;hot dog&#39;</span><span class="p">,</span> <span class="s1">&#39;pizza&#39;</span><span class="p">,</span> <span class="s1">&#39;donut&#39;</span><span class="p">,</span> <span class="s1">&#39;cake&#39;</span><span class="p">,</span>
        <span class="s1">&#39;chair&#39;</span><span class="p">,</span> <span class="s1">&#39;couch&#39;</span><span class="p">,</span> <span class="s1">&#39;potted plant&#39;</span><span class="p">,</span> <span class="s1">&#39;bed&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;dining table&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span>
        <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;toilet&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span> <span class="s1">&#39;tv&#39;</span><span class="p">,</span> <span class="s1">&#39;laptop&#39;</span><span class="p">,</span> <span class="s1">&#39;mouse&#39;</span><span class="p">,</span> <span class="s1">&#39;remote&#39;</span><span class="p">,</span> <span class="s1">&#39;keyboard&#39;</span><span class="p">,</span>
        <span class="s1">&#39;cell phone&#39;</span><span class="p">,</span> <span class="s1">&#39;microwave&#39;</span><span class="p">,</span> <span class="s1">&#39;oven&#39;</span><span class="p">,</span> <span class="s1">&#39;toaster&#39;</span><span class="p">,</span> <span class="s1">&#39;sink&#39;</span><span class="p">,</span> <span class="s1">&#39;refrigerator&#39;</span><span class="p">,</span> <span class="s1">&#39;N/A&#39;</span><span class="p">,</span>
        <span class="s1">&#39;book&#39;</span><span class="p">,</span> <span class="s1">&#39;clock&#39;</span><span class="p">,</span> <span class="s1">&#39;vase&#39;</span><span class="p">,</span> <span class="s1">&#39;scissors&#39;</span><span class="p">,</span> <span class="s1">&#39;teddy bear&#39;</span><span class="p">,</span> <span class="s1">&#39;hair drier&#39;</span><span class="p">,</span>
        <span class="s1">&#39;toothbrush&#39;</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="c1"># Create a transform to pre-process the images into a format acceptable by the DETR model.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
            <span class="n">T</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">800</span><span class="p">),</span>
            <span class="n">T</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">T</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
        <span class="p">])</span>

        <span class="c1"># Build a dict translating the classes DETR was trained on to the classes YOLO was trained on.</span>
        <span class="c1"># DETR classes, listed in DETR_CLASSES, include &#39;N/A&#39; classes which didn&#39;t exist in the YOLO version of COCO</span>
        <span class="c1"># data.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_translation</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">detr_shift</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">DETR_CLASSES</span><span class="p">)):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">DETR_CLASSES</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;N/A&#39;</span><span class="p">:</span>
                <span class="n">detr_shift</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">label_translation</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span> <span class="o">-</span> <span class="n">detr_shift</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">batch_to_labels</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert the batch to a list of labels. Copied from deepchecks.vision.datasets.detection.coco&quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">move_class</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">device</span><span class="p">))</span> \
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">tensor</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">move_class</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">batch_to_images</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert the batch to a list of images. Copied from deepchecks.vision.datasets.detection.coco&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

    <span class="k">def</span> <span class="nf">_detect</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">im</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A helper function. Applies DETR detection to a single PIL image.&quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">box_cxcywh_to_xyxy</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Convert bounding box format from [cx, cy, w, h] to [xmin, ymin, xmax, ymax], when c is &quot;center&quot;.&quot;&quot;&quot;</span>
            <span class="n">x_c</span><span class="p">,</span> <span class="n">y_c</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">b</span> <span class="o">=</span> <span class="p">[(</span><span class="n">x_c</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">w</span><span class="p">),</span> <span class="p">(</span><span class="n">y_c</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">h</span><span class="p">),</span>
                 <span class="p">(</span><span class="n">x_c</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">w</span><span class="p">),</span> <span class="p">(</span><span class="n">y_c</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">h</span><span class="p">)]</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">rescale_bboxes</span><span class="p">(</span><span class="n">out_bbox</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Rescale bounding boxes from the DETR model&#39;s normalized output to the original image size.&quot;&quot;&quot;</span>
            <span class="n">img_w</span><span class="p">,</span> <span class="n">img_h</span> <span class="o">=</span> <span class="n">size</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">box_cxcywh_to_xyxy</span><span class="p">(</span><span class="n">out_bbox</span><span class="p">)</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">img_w</span><span class="p">,</span> <span class="n">img_h</span><span class="p">,</span> <span class="n">img_w</span><span class="p">,</span> <span class="n">img_h</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">b</span>

        <span class="c1"># Apply the transform to the image.</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">(</span><span class="n">im</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># propagate through the model</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

        <span class="c1"># keep only predictions with 0.7+ confidence</span>
        <span class="n">probas</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logits&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
        <span class="n">keep</span> <span class="o">=</span> <span class="n">probas</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span> <span class="o">&gt;</span> <span class="mf">0.7</span>

        <span class="c1"># convert boxes from [0; 1] normalized units to image scales.</span>
        <span class="n">bboxes_scaled</span> <span class="o">=</span> <span class="n">rescale_bboxes</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;pred_boxes&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="n">keep</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">im</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">probas</span><span class="p">[</span><span class="n">keep</span><span class="p">],</span> <span class="n">bboxes_scaled</span>

    <span class="k">def</span> <span class="nf">_convert_to_80_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Use the pre-built self.label_translation to translate the DETR predictions to YOLO COCO classes.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">label_translation</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">infer_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Infer on a batch of images and return it in deepchecks format.</span>

<span class="sd">        Return a list of prediction tensors (one for each image) containing in each row:</span>
<span class="sd">        [x_min, y_min, width, height, confidence, class_id]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">processed_preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Iterate over images in the batch</span>
        <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>

            <span class="n">probas</span><span class="p">,</span> <span class="n">bboxes_scaled</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_detect</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">batch_idx</span><span class="p">],</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
            <span class="n">bboxes_scaled</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">=</span> <span class="n">bboxes_scaled</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">-</span> <span class="n">bboxes_scaled</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># xyxy to xywh</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">probas</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">processed_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">bboxes_scaled</span><span class="p">,</span>  <span class="c1"># xywh bbox coordinates</span>
                                            <span class="n">probas</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>  <span class="c1"># confidence</span>
                                            <span class="bp">self</span><span class="o">.</span><span class="n">_convert_to_80_labels</span><span class="p">(</span><span class="n">probas</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">())],</span>
                                           <span class="c1"># translated class id</span>
                                           <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">processed_preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">processed_pred</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">processed_preds</span>

</pre></div>
</div>
<p>We can now create <a class="reference internal" href="../../api/generated/deepchecks.vision.vision_data.VisionData.html#deepchecks.vision.vision_data.VisionData" title="deepchecks.vision.vision_data.VisionData"><code class="xref py py-class docutils literal notranslate"><span class="pre">VisionData</span></code></a> object. This deepchecks object accepts
a batch loader, which is an iterator that yields batches of images, labels, predictions and any other required
information. To read more about it, see the <a class="reference internal" href="../vision/VisionData.html"><span class="doc">Vision Data Guide</span></a>. In this example
our batch loader is a python dataloader, so we’ll create a custom collate function that will convert the data to the
required formats and generate the predictions. We’ll then use the <a class="reference internal" href="../../api/generated/deepchecks.vision.vision_data.VisionData.head.html#deepchecks.vision.vision_data.VisionData.head" title="deepchecks.vision.vision_data.VisionData.head"><code class="xref py py-meth docutils literal notranslate"><span class="pre">head</span></code></a>
method to make sure the dataset was created successfully.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deepchecks.vision.datasets.detection</span> <span class="kn">import</span> <span class="n">coco_torch</span> <span class="k">as</span> <span class="n">coco</span>
<span class="kn">from</span> <span class="nn">deepchecks.vision.datasets.detection</span> <span class="kn">import</span> <span class="n">coco_utils</span>
<span class="kn">from</span> <span class="nn">deepchecks.vision.vision_data</span> <span class="kn">import</span> <span class="n">BatchOutputFormat</span>

<span class="n">detr_train_datalaoder</span> <span class="o">=</span> <span class="n">coco</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">object_type</span><span class="o">=</span><span class="s1">&#39;DataLoader&#39;</span><span class="p">)</span>
<span class="n">detr_test_datalaoder</span> <span class="o">=</span> <span class="n">coco</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">object_type</span><span class="o">=</span><span class="s1">&#39;DataLoader&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">deepchecks_collate_fn_generator</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generates a collate function that converts the batch to the deepchecks format, using the given model.&quot;&quot;&quot;</span>

    <span class="n">detr_formatter</span> <span class="o">=</span> <span class="n">COCODETRData</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">deepchecks_collate_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A collate function that converts the batch to the format expected by deepchecks.&quot;&quot;&quot;</span>

        <span class="c1"># Reproduce the steps of the default collate function</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">))</span>

        <span class="n">images</span> <span class="o">=</span> <span class="n">detr_formatter</span><span class="o">.</span><span class="n">batch_to_images</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">detr_formatter</span><span class="o">.</span><span class="n">batch_to_labels</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">detr_formatter</span><span class="o">.</span><span class="n">infer_on_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">BatchOutputFormat</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">deepchecks_collate_fn</span>


<span class="n">detr_test_datalaoder</span><span class="o">.</span><span class="n">collate_fn</span> <span class="o">=</span> <span class="n">deepchecks_collate_fn_generator</span><span class="p">(</span><span class="n">detr_resnet</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="n">detr_test_ds</span> <span class="o">=</span> <span class="n">VisionData</span><span class="p">(</span><span class="n">detr_test_datalaoder</span><span class="p">,</span> <span class="n">task_type</span><span class="o">=</span><span class="s1">&#39;object_detection&#39;</span><span class="p">,</span> <span class="n">label_map</span><span class="o">=</span><span class="n">coco_utils</span><span class="o">.</span><span class="n">LABEL_MAP</span><span class="p">)</span>

<span class="n">detr_test_ds</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>

</pre></div>
</div>
<img alt="Validating" class="align-left" src="../../_images/detr_valid.png" />
<p>Great! We can see that the labels match the object locations, and that the labels an detections align.</p>
</section>
<section id="load-pre-made-yolov5s">
<h2>Load Pre-Made YOLOv5s<a class="headerlink" href="#load-pre-made-yolov5s" title="Permalink to this headline">#</a></h2>
<p>Next, we’ll load from <a class="reference internal" href="../../api/generated/deepchecks.vision.datasets.detection.coco_torch.html#module-deepchecks.vision.datasets.detection.coco_torch" title="deepchecks.vision.datasets.detection.coco_torch"><code class="xref py py-mod docutils literal notranslate"><span class="pre">deepchecks.vision.datasets.detection.coco_torch</span></code></a> a VisionData containing a sample of the COCO dataset (coco 128)
complete with YOLO predictions on this dataset, both downloaded from <a class="reference external" href="https://github.com/ultralytics/yolov5">ultralytics</a> repository. We’ll use yolo
to benchmark the results achieved by the DETR model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">yolo_test_ds</span> <span class="o">=</span> <span class="n">coco</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="n">object_type</span><span class="o">=</span><span class="s1">&#39;VisionData&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

</pre></div>
</div>
<p>We already loaded the data wrapped with the relevant <code class="docutils literal notranslate"><span class="pre">VisionData</span></code> object, so we can just use the
<a class="reference internal" href="../../checks_gallery/vision/model_evaluation/plot_mean_average_precision_report.html"><span class="doc">MeanAveragePrecisionReport</span></a> check to
evaluate the model’s performance for various IoU thresholds and bounding box sizes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">deepchecks.vision.checks</span> <span class="kn">import</span> <span class="n">MeanAveragePrecisionReport</span>

<span class="n">yolo_map_result</span> <span class="o">=</span> <span class="n">MeanAveragePrecisionReport</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">yolo_test_ds</span><span class="p">)</span>
<span class="n">yolo_map_result</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

</pre></div>
</div>
<img alt="Mean Average Precision Report for Yolov5" class="align-center" src="../../_images/yolo_map.png" />
</section>
<section id="benchmarking-yolov5s-against-detr-resnet">
<h2>Benchmarking YOLOv5s Against DETR ResNet<a class="headerlink" href="#benchmarking-yolov5s-against-detr-resnet" title="Permalink to this headline">#</a></h2>
<p>Now that we have everything in place, we can run the
<a class="reference internal" href="../../checks_gallery/vision/model_evaluation/plot_mean_average_precision_report.html"><span class="doc">MeanAveragePrecisionReport</span></a> check
also on the DETR model! Let’s run and compare to the YOLO results.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># The test data contains the same dataloader as the yolo_test_ds, the only difference being them being wrapped by</span>
<span class="c1"># different subclasses of DetectionData facilitating the interface to the different models.</span>
<span class="n">detr_map_result</span> <span class="o">=</span> <span class="n">MeanAveragePrecisionReport</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">detr_test_ds</span><span class="p">)</span>
<span class="n">detr_map_result</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

</pre></div>
</div>
<img alt="Mean Average Precision Report for DETR ResNet" class="align-center" src="../../_images/detr_map.png" />
<p>Comparing to the results achieved earlier with YOLO:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">yolo_map_result</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

</pre></div>
</div>
<img alt="Mean Average Precision Report for Yolov5" class="align-center" src="../../_images/yolo_map.png" />
<p>We can clearly see an improvement in the DETR model! We can further see that the greatest improvement has been achieved
for the larger objects, with objects of sizes of up to 32^2 squared pixels improving only from an mAP of
0.21 to 0.26.</p>
<p>Of course, now that the VisionData object has been implemented you can use any of the other deepchecks check and suites.
You can check them out in our <a class="reference internal" href="../../checks_gallery/vision.html"><span class="doc">check gallery</span></a>, and learn more about
<a class="reference internal" href="../general/when_should_you_use.html#when-should-you-use-deepchecks"><span class="std std-ref">when you should use</span></a> each of our built-in suites.</p>
</section>
</section>


            </div>
        
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="h2o.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">H2O</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="airflow.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Airflow</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
    </main>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021-2023, Deepchecks.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>