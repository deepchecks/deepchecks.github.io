{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image Property Drift {#plot_vision_image_property_drift}\n====================\n\nThis notebooks provides an overview for using and understanding the\nimage property drift check.\n\n**Structure:**\n\n-   [What Is Image Drift?](#what-is-image-drift)\n-   [Which Image Properties Are Used?](#which-image-properties-are-used)\n-   [Prepare data](#prepare-data)\n-   [Run the check](#run-the-check)\n-   [Define a condition](#define-a-condition)\n-   [Check Parameters](#check-parameters)\n\nWhat Is Image Drift?\n--------------------\n\nDrift is simply a change in the distribution of data over time, and it\nis also one of the top reasons why machine learning model\\'s performance\ndegrades over time.\n\nImage drift is a data drift that occurs in images in the dataset.\n\nFor more information on drift, please visit our\n`drift guide </user-guide/general/drift_guide>`{.interpreted-text\nrole=\"doc\"}.\n\n### How Deepchecks Detects Image Drift\n\nThis check detects image property drift by using\n`univariate measures <drift_detection_by_univariate_measure>`{.interpreted-text\nrole=\"ref\"} on each image property separately. Another possible method\nfor drift detection is by\n`a domain classifier <drift_detection_by_domain_classifier>`{.interpreted-text\nrole=\"ref\"} which is used in the\n`Image Dataset Drift check </checks_gallery/vision/train_test_validation/plot_image_dataset_drift>`{.interpreted-text\nrole=\"doc\"}.\n\n### Using Properties to Detect Image Drift\n\nIn computer vision specifically, we can\\'t measure drift on images\ndirectly, as the individual pixel has little value when estimating\ndrift. Therefore, we calculate drift on different\n`properties of the image</user-guide/vision/vision_properties>`{.interpreted-text\nrole=\"doc\"}, on which we can directly measure drift.\n\nWhich Image Properties Are Used?\n--------------------------------\n\n  Property name                   What is it\n  ------------------------------- ----------------------------------------------------------------------------------------------------------------------------------------\n  Aspect Ratio                    Ratio between height and width of image (height / width)\n  Area                            Area of image in pixels (height \\* width)\n  Brightness                      Average intensity of image pixels. Color channels have different weights according to RGB-to-Grayscale formula\n  RMS Contrast                    Contrast of image, calculated by standard deviation of pixels\n  Mean Red Relative Intensity     Mean over all pixels of the red channel, scaled to their relative intensity in comparison to the other channels \\[r / (r + g + b)\\].\n  Mean Green Relative Intensity   Mean over all pixels of the green channel, scaled to their relative intensity in comparison to the other channels \\[g / (r + g + b)\\].\n  Mean Blue Relative Intensity    Mean over all pixels of the blue channel, scaled to their relative intensity in comparison to the other channels \\[b / (r + g + b)\\].\n\n### Imports\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.note}\n::: {.title}\nNote\n:::\n\nIn this example, we use the pytorch version of the coco dataset and\nmodel. In order to run this example using tensorflow, please change the\nimport statements to:\n\nfrom deepchecks.vision.datasets.detection import coco\\_tensorflow as\ncoco\n:::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.checks import ImagePropertyDrift\nfrom deepchecks.vision.datasets.detection import coco_torch as coco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare data\n============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.utils import image_properties\n\ntrain_dataset = coco.load_dataset(train=True, object_type='VisionData')\ntest_dataset = coco.load_dataset(train=False, object_type='VisionData')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check\n=============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check_result = ImagePropertyDrift().run(train_dataset, test_dataset)\ncheck_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To display the results in an IDE like PyCharm, you can use the following\ncode:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#  check_result.show_in_window()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result will be displayed in a new window.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe the check's output\n==========================\n\nThe result value is a pandas DataFrame that contains drift score for\neach image property.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check_result.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also pass the check a list of classes we wish to inspect, and the\ncheck will calculate the properties only for images either belonging to\nthe classes or containing annotations belonging to the classes. (We\\'ll\nlower the min\\_samples to 5 to tell the check to calculate drift despite\nhaving only a few images left after the class filtration)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check_result = ImagePropertyDrift(classes_to_display=['person', 'traffic light'], min_samples=5\n                                  ).run(train_dataset, test_dataset)\ncheck_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a condition\n==================\n\nWe can define a condition that make sure that image properties drift\nscores do not exceed allowed threshold.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check_result = (\n    ImagePropertyDrift()\n    .add_condition_drift_score_less_than(0.001)\n    .run(train_dataset, test_dataset)\n)\ncheck_result.show(show_additional_outputs=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check Parameters\n================\n\nImage Property Drift Check accepts two parameters that allows us to\ncontrol the look of the output:\n\n-   [vision\\_properties]{.title-ref} - list of image properties that we\n    are interested in\n-   [max\\_num\\_categories]{.title-ref} - Maximal number of categories to\n    use for the calculation of drift using PSI (Population Stability\n    Index)\n\nOnly next string values are allowed for the\n[vision\\_properties]{.title-ref} parameter:\n\n-   [aspect\\_ratio]{.title-ref}\n-   [area]{.title-ref}\n-   [brightness]{.title-ref}\n-   [mean\\_red\\_relative\\_intensity]{.title-ref}\n-   [mean\\_green\\_relative\\_intensity]{.title-ref}\n-   [mean\\_blue\\_relative\\_intensity]{.title-ref}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from typing import List\n\nimport numpy as np\n\n\ndef area(images: List[np.ndarray]) -> List[int]:\n    # Return list of integers of image areas (height multiplied by width)\n    return [img.shape[0] * img.shape[1] for img in images]\n\n\ndef aspect_ratio(images: List[np.ndarray]) -> List[float]:\n    # Return list of floats of image height to width ratio\n    return [img.shape[0] / img.shape[1] for img in images]\n\n\nproperties = [\n    {'name': 'Area', 'method': area, 'output_type': 'numerical'},\n    {'name': 'Aspect Ratio', 'method': aspect_ratio, 'output_type': 'numerical'}\n]\n\ncheck_result = ImagePropertyDrift(\n    image_properties=properties,\n    max_num_categories_for_drift=20\n).run(train_dataset, test_dataset)\n\ncheck_result"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}