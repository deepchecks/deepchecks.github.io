{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image Dataset Drift\n===================\n\nThis notebooks provides an overview for using and understanding the\nimage dataset drift check, used to detect drift in simple image\nproperties between train and test datasets.\n\n**Structure:**\n\n-   [What Is Image Dataset Drift?](#what-is-image-dataset-drift)\n-   [Which Image Properties Are Used?](#which-image-properties-are-used)\n-   [Loading The Data](#loading-the-data)\n-   [Run The Check](#run-the-check)\n\nWhat Is Image Dataset Drift?\n----------------------------\n\nDrift is simply a change in the distribution of data over time, and it\nis also one of the top reasons why machine learning model\\'s performance\ndegrades over time.\n\nImage dataset drift is a drift that occurs in more than one image\nproperty at a time, and may even affect the relationships between those\nproperties, which are undetectable by univariate drift methods.\n\nFor more information on drift, please visit our\n`drift guide </user-guide/general/drift_guide>`{.interpreted-text\nrole=\"doc\"}.\n\nHow Deepchecks Detects Dataset Drift\n------------------------------------\n\nThis check detects multivariate drift by using\n`a domain classifier <drift_detection_by_domain_classifier>`{.interpreted-text\nrole=\"ref\"}. Other methods to detect drift include\n`univariate measures <drift_detection_by_univariate_measure>`{.interpreted-text\nrole=\"ref\"} which is used in other checks, such as\n`Image Property Drift check </checks_gallery/vision/train_test_validation/plot_image_property_drift>`{.interpreted-text\nrole=\"doc\"}.\n\nUsing Properties to Detect Image Drift\n--------------------------------------\n\nIn computer vision specifically, we can\\'t measure drift on the images\ndirectly, as the individual pixel has little value when estimating\ndrift. Therefore, we calculate drift on different\n`properties of the image</user-guide/vision/vision_properties>`{.interpreted-text\nrole=\"doc\"}, on which we can directly measure drift.\n\nWhich Image Properties Are Used?\n--------------------------------\n\n  Property name                   What is it\n  ------------------------------- ----------------------------------------------------------------------------------------------------------------------------------------\n  Aspect Ratio                    Ratio between height and width of image (height / width)\n  Area                            Area of image in pixels (height \\* width)\n  Brightness                      Average intensity of image pixels. Color channels have different weights according to RGB-to-Grayscale formula\n  RMS Contrast                    Contrast of image, calculated by standard deviation of pixels\n  Mean Red Relative Intensity     Mean over all pixels of the red channel, scaled to their relative intensity in comparison to the other channels \\[r / (r + g + b)\\].\n  Mean Green Relative Intensity   Mean over all pixels of the green channel, scaled to their relative intensity in comparison to the other channels \\[g / (r + g + b)\\].\n  Mean Blue Relative Intensity    Mean over all pixels of the blue channel, scaled to their relative intensity in comparison to the other channels \\[b / (r + g + b)\\].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imports\n=======\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom deepchecks.vision.checks import ImageDatasetDrift\nfrom deepchecks.vision.datasets.detection.coco import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading the data\n================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_ds = load_dataset(train=True, object_type='VisionData')\ntest_ds = load_dataset(train=False, object_type='VisionData')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check\n=============\n\nwithout drift\n-------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = ImageDatasetDrift()\ncheck.run(train_dataset=train_ds, test_dataset=test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insert drift\n============\n\nNow, we will define a custom data object that will insert a drift to the\ntraining set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.datasets.detection.coco import COCOData\n\n\ndef add_brightness(img):\n    reverse = 255 - img\n    addition_of_brightness = (reverse * 0.07).astype(int)\n    return img + addition_of_brightness\n\n\nclass DriftedCOCO(COCOData):\n    \n    def batch_to_images(self, batch):\n        return [add_brightness(np.array(img)) for img in batch[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_dataloader = load_dataset(train=True, object_type='DataLoader')\ntest_dataloader = load_dataset(train=False, object_type='DataLoader')\n\ndrifted_train_ds = DriftedCOCO(train_dataloader)\ntest_ds = COCOData(test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check again\n===================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = ImageDatasetDrift()\ncheck.run(train_dataset=drifted_train_ds, test_dataset=test_ds)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}