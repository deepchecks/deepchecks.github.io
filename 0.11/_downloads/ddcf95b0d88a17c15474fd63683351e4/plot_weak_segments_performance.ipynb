{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Weak Segments Performance\n=========================\n\nThis notebook provides an overview for using and understanding the weak\nsegment performance check.\n\n**Structure:**\n\n-   [What is the purpose of the\n    check?](#what-is-the-purpose-of-the-check)\n-   [Automatically detecting weak\n    segments](#automatically-detecting-weak-segments)\n-   [Generate Dataset](#generate-dataset)\n-   [Run the check](#run-the-check)\n-   [Define a condition](#define-a-condition)\n\nWhat is the purpose of the check?\n---------------------------------\n\nThe check is designed to easily identify the model\\'s weakest segments.\nThe segments are characterized by the\n`image properties </user-guide/vision/vision_properties>`{.interpreted-text\nrole=\"doc\"} such as contrast and aspect ratio.\n\nAutomatically detecting weak segments\n-------------------------------------\n\nThe check performs several steps:\n\n1.  We calculate the image properties for each sample. The properties to\n    calculate can be passed explicitly or resort to the default image\n    properties.\n2.  We calculate loss for each sample in the dataset using the provided\n    model or predictions, the loss function can be passed explicitly or\n    set to a default based on the task type.\n3.  We train multiple simple tree based models, each one is trained\n    using two properties to predict the per sample error calculated\n    before.\n4.  We convert each of the leafs in each of the trees into a segment and\n    calculate the segment\\'s performance. For the weakest segments\n    detected we also calculate the model\\'s performance on the data\n    segments surrounding them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate Dataset\n================\n\n::: {.note}\n::: {.title}\nNote\n:::\n\nIn this example, we use the pytorch version of the coco dataset and\nmodel. In order to run this example using tensorflow, please change the\nimport statements to:\n\nfrom deepchecks.vision.datasets.detection import coco\\_tensorflow as\ncoco\n:::\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.checks import WeakSegmentsPerformance\nfrom deepchecks.vision.datasets.detection import coco_torch as coco\n\ncoco_data = coco.load_dataset(train=False, object_type='VisionData')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check\n=============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = WeakSegmentsPerformance()\nresult = check.run(coco_data)\nresult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To display the results in an IDE like PyCharm, you can use the following\ncode:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#  result.show_in_window()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result will be displayed in a new window. %% Observe the check\\'s\noutput \\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\--\n\n> We see in the results that the check indeed found several segments on\n> which the model performance is below average. In the heatmap display\n> we can see the model\\'s performance on the weakest segments and their\n> environment with respect to the two segmentation features. In order to\n> get the full list of weak segments found we can look at the\n> result.value attribute.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result.value['weak_segments_list']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we will run a check with properties and minimum segment size ratio\n(the minimal fraction of the data to be considered as a segment)\ndifferent from the defaults.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.utils.image_properties import brightness, texture_level\nproperties = [{'name': 'brightness', 'method': brightness, 'output_type': 'numerical'},\n              {'name': ' texture', 'method': texture_level, 'output_type': 'numerical'}]\ncheck = WeakSegmentsPerformance(segment_minimum_size_ratio=0.03, image_properties=properties)\nresult = check.run(coco_data)\nresult.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a condition\n==================\n\nWe can define on our check a condition that will validate that the ratio\nof the model performance on the weakest segment to the average model\nperformance is less than a specified ratio.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Let's add a condition and re-run the check:\n\ncheck.add_condition_segments_relative_performance_greater_than(0.1)\nresult = check.run(coco_data)\nresult.show(show_additional_outputs=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}