{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Text Property Outliers {#nlp__text_property_outliers}\n======================\n\nThis notebooks provides an overview for using and understanding the text\nproperty outliers check, used to detect outliers in simple text\nproperties in a dataset.\n\n**Structure:**\n\n-   [Why Check for Outliers?](#why-check-for-outliers)\n-   [How Does the Check Work?](#how-does-the-check-work)\n-   [Which Text Properties Are Used?](#which-text-properties-are-used)\n-   [Run the Check](#run-the-check)\n\nWhy Check for Outliers?\n-----------------------\n\nExamining outliers may help you gain insights that you couldn\\'t have\nreached from taking an aggregate look or by inspecting random samples.\nFor example, it may help you understand you have some corrupt samples\n(e.g. texts without spaces between words), or samples you didn\\'t expect\nto have (e.g. texts in Norwegian instead of English). In some cases,\nthese outliers may help debug some performance discrepancies (the model\ncan be excused for failing on a totally blank text). In more extreme\ncases, the outlier samples may indicate the presence of samples\ninterfering with the model\\'s training by teaching the model to fit\n\\\"irrelevant\\\" samples.\n\nHow Does the Check Work?\n------------------------\n\nIdeally we would like to directly find text samples which are outliers,\nbut this is computationally expensive and does not have a clear and\nexplainable results. Therefore, we use text properties in order to find\noutliers (such as text length, average word length, language etc.) which\nare much more efficient to compute, and each outlier is easily\nexplained.\n\n-   For numeric properties (such as \\\"percent of special characters\\\"),\n    we use [Interquartile\n    Range](https://en.wikipedia.org/wiki/Interquartile_range#Outliers)\n    to define our upper and lower limit for the properties\\' values.\n-   For categorical properties (such as \\\"language\\\"), we look for a\n    \\\"sharp drop\\\" in the category distribution to define our lower\n    limit for the properties\\' values. This method is based on the\n    assumption that the distribution of categories in the dataset is\n    \\\"smooth\\\" and differences in the commonality of categories are\n    gradual. For example, in a clean dataset, if the distribution of\n    English texts is 80%, the distribution of the next most common\n    language would be of similar scale (e.g. 10%) and so forth. If we\n    find a category that has a much lower distribution than the rest, we\n    assume that this category and even smaller categories are outliers.\n\n### Which Text Properties Are Used?\n\nBy default the checks use the built-in text properties, and it\\'s also\npossible to replace the default properties with custom ones. For the\nlist of the built-in text properties and explanation about custom\nproperties refer to\n`NLP properties <nlp__properties_guide>`{.interpreted-text role=\"ref\"}.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the Check\n=============\n\nFor this example, we\\'ll use the tweet emotion dataset, which is a\ndataset of tweets labeled by one of four emotions: happiness, anger,\nsadness and optimism.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.nlp.checks import TextPropertyOutliers\nfrom deepchecks.nlp.datasets.classification import tweet_emotion\n\ndataset = tweet_emotion.load_data(as_train_test=False)\n\ncheck = TextPropertyOutliers()\nresult = check.run(dataset)\nresult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe Graphic Result\n======================\n\nIn this example, we can find many tweets that are outliers - For\nexample, in the \\\"average word length\\\" property, we can see that there\nare tweets with a very large average word length, which is is usually\nbecause of missing spaces in the tweet itself, or the fact that tweeter\nhashtags remained in the data and they don\\'t contain spaces. This could\nbe problematic for the model, as it cannot coprehend the hashtags as\nwords, and it may cause the model to fail on these tweets.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}