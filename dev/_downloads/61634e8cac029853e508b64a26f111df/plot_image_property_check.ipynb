{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image Property Drift Check\n==========================\n\nThis notebooks provides an overview for using and understanding the\nimage property drift check.\n\n**Structure:**\n\n-   [How Does the ImagePropertyDrift Check\n    Work?](#how-does-the-imagepropertydrift-check-work)\n-   [Which Image Properties Are Used?](#which-image-properties-are-used)\n-   [Prepare data](#prepare-data)\n-   [Run the check](#run-the-check)\n-   [Define a condition](#define-a-condition)\n-   [Check Parameters](#check-parameters)\n\nHow Does the ImagePropertyDrift Check Work?\n================================= Data drift is simply a change in the\ndistribution of data over time. It is also one of the top reasons that a\nmachine learning model performance degrades over time.\n\nIn the context of machine learning, drift between the training set and\nthe test set will likely make the model prone to errors. In other words,\nif the model was trained on data that is different from the current test\ndata, it will probably make more mistakes predicting the target\nvariable.\n\nThe Image Property Drift check calculates a drift score for each image\nproperty in the test dataset, by comparing its distribution to the train\ndataset. For this, we use the Earth Movers Distance (Wasserstein\ndistance).\n\nWhich Image Properties Are Used?\n--------------------------------\n\n  Property name                   What is it\n  ------------------------------- ----------------------------------------------------------------------------------------------------------------------------------------\n  Aspect Ratio                    Ratio between height and width of image (height / width)\n  Area                            Area of image in pixels (height \\* width)\n  Brightness                      Average intensity of image pixels. Color channels have different weights according to RGB-to-Grayscale formula\n  RMS Contrast                    Contrast of image, calculated by standard deviation of pixels\n  Mean Red Relative Intensity     Mean over all pixels of the red channel, scaled to their relative intensity in comparison to the other channels \\[r / (r + g + b)\\].\n  Mean Green Relative Intensity   Mean over all pixels of the green channel, scaled to their relative intensity in comparison to the other channels \\[g / (r + g + b)\\].\n  Mean Blue Relative Intensity    Mean over all pixels of the blue channel, scaled to their relative intensity in comparison to the other channels \\[b / (r + g + b)\\].\n\n### Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.datasets.detection import coco\nfrom deepchecks.vision.checks.distribution import ImagePropertyDrift"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare data\n============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.utils import image_properties\n\ntrain_dataset = coco.load_dataset(train=True, object_type='VisionData')\ntest_dataset = coco.load_dataset(train=False, object_type='VisionData')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check\n=============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check_result = ImagePropertyDrift().run(train_dataset, test_dataset)\ncheck_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe the check's output\n==========================\n\nThe result value is a pandas DataFrame that contains drift score for\neach image property.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check_result.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also pass the check a list of classes we wish to inspect, and the\ncheck will calculate the properties only for images either belonging to\nthe classes or containing annotations belonging to the classes. (We\\'ll\nlower the min\\_samples to 5 to tell the check to calculate drift despite\nhaving only a few images left after the class filtration)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check_result = ImagePropertyDrift(classes_to_display=['person', 'cat', 'cell phone', 'car'], min_samples=5\n                                  ).run(train_dataset, test_dataset)\ncheck_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a condition\n==================\n\nWe can define a condition that make sure that image properties drift\nscores do not exceed allowed threshold.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check_result = (\n    ImagePropertyDrift()\n    .add_condition_drift_score_not_greater_than(0.001)\n    .run(train_dataset, test_dataset)\n)\ncheck_result.show(show_additional_outputs=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check Parameters\n================\n\nImage Property Drift Check accepts two parameters that allows us to\ncontrol the look of the output:\n\n-   [image\\_properties]{.title-ref} - list of image properties that we\n    are interested in\n-   [max\\_num\\_categories]{.title-ref} - Maximal number of categories to\n    use for the calculation of drift using PSI (Population Stability\n    Index)\n\nOnly next string values are allowed for the\n[image\\_properties]{.title-ref} parameter:\n\n-   [aspect\\_ratio]{.title-ref}\n-   [area]{.title-ref}\n-   [brightness]{.title-ref}\n-   [mean\\_red\\_relative\\_intensity]{.title-ref}\n-   [mean\\_green\\_relative\\_intensity]{.title-ref}\n-   [mean\\_blue\\_relative\\_intensity]{.title-ref}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from typing import List\nimport numpy as np\n\n\ndef area(images: List[np.ndarray]) -> List[int]:\n    # Return list of integers of image areas (height multiplied by width)\n    return [img.shape[0] * img.shape[1] for img in images]\n\n\ndef aspect_ratio(images: List[np.ndarray]) -> List[float]:\n    # Return list of floats of image height to width ratio\n    return [img.shape[0] / img.shape[1] for img in images]\n\n\nproperties = [\n    {'name': 'Area', 'method': area, 'output_type': 'continuous'},\n    {'name': 'Aspect Ratio', 'method': aspect_ratio, 'output_type': 'continuous'}\n]\n\ncheck_result = ImagePropertyDrift(\n    image_properties=properties,\n    max_num_categories=20\n).run(train_dataset, test_dataset)\n\ncheck_result"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}