{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Weak Segments Performance\n=========================\n\nThis notebook provides an overview for using and understanding the weak\nsegment performance check.\n\n**Structure:**\n\n-   [What is the purpose of the\n    check?](#what-is-the-purpose-of-the-check)\n-   [Automatically detecting weak\n    segments](#automatically-detecting-weak-segments)\n-   [Generate data & model](#generate-data-model)\n-   [Run the check](#run-the-check)\n-   [Define a condition](#define-a-condition)\n\nWhat is the purpose of the check?\n---------------------------------\n\nThe check is designed to help you easily identify the model\\'s weakest\nsegments in the data provided. In addition, it enables to provide a\nsublist of the Dataset\\'s features, thus limiting the check to search in\ninteresting subspaces.\n\nAutomatically detecting weak segments\n-------------------------------------\n\nThe check contains several steps:\n\n1.  We calculate loss for each sample in the dataset using the provided\n    model via either log-loss or MSE according to the task type.\n2.  Select a subset of features for the weak segment search. This is\n    done by selecting the features with the highest feature importance\n    to the model provided (within the features selected for check, if\n    limited).\n3.  We train multiple simple tree based models, each one is trained\n    using exactly two features (out of the ones selected above) to\n    predict the per sample error calculated before.\n4.  We convert each of the leafs in each of the trees into a segment and\n    calculate the segment\\'s performance. For the weakest segments\n    detected we also calculate the model\\'s performance on data segments\n    surrounding them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate data & model\n=====================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.datasets.classification.phishing import (\n    load_data, load_fitted_model)\n\ntrain_dataset, test_dataset = load_data()\nmodel = load_fitted_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check\n=============\n\nThe check has several key parameters (that are all optional) that affect\nthe behavior of the check and especially its output.\n\n`columns / ignore_columns`: Controls which columns should be searched\nfor weak segments. By default, a heuristic is used to determine which\ncolumns to use based solely on their feature importance.\n\n`alternative_scorer`: Determines the metric to be used as the\nperformance measurement of the model on different segments. It is\nimportant to select a metric that is relevant to the data domain and\ntask you are performing. By default, the check uses Neg RMSE for\nregression tasks and Accuracy for classification tasks.\n\n`segment_minimum_size_ratio`: Determines the minimum size of segments\nthat are of interest. The check is tuned to find the weakest segment\nregardless of the segment size and so it is recommended to try different\nconfigurations of this parameter as larger segments can be of interest\neven the model performance on them is superior.\n\n`categorical_aggregation_threshold`: By default the check will combine\nrare categories into a single category called \\\"Other\\\". This parameter\ndetermines the frequency threshold for categories to be mapped into to\nthe \\\"other\\\" category.\n\nsee\n`API reference <deepchecks.tabular.checks.model_evaluation.WeakSegmentsPerformance>`{.interpreted-text\nrole=\"class\"} for more details.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.datasets.classification import phishing\nfrom deepchecks.tabular.checks import WeakSegmentsPerformance\nfrom sklearn.metrics import make_scorer, f1_score\n\nscorer = {'f1': make_scorer(f1_score, average='micro')}\n_, test_ds = phishing.load_data()\nmodel = phishing.load_fitted_model()\ncheck = WeakSegmentsPerformance(columns=['urlLength', 'numTitles', 'ext', 'entropy'],\n                                alternative_scorer=scorer,\n                                segment_minimum_size_ratio=0.03,\n                                categorical_aggregation_threshold=0.05)\nresult = check.run(test_ds, model)\nresult.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe the check\\'s output\n===========================\n\nWe see in the results that the check indeed found several segments on\nwhich the model performance is below average. In the heatmap display we\ncan see model performance on the weakest segments and their environment\nwith respect to the two features that are relevant to the segment. In\norder to get the full list of weak segments found we will inspect the\nresult.value attribute.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result.value['weak_segments_list']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a condition\n==================\n\nWe can define on our check a condition that will validate that the model\nperformance on the weakest segment detected is greater than a specified\nratio of the average model performance of the entire dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Let's add a condition and re-run the check:\n\ncheck = WeakSegmentsPerformance(alternative_scorer=scorer, segment_minimum_size_ratio=0.03)\ncheck.add_condition_segments_relative_performance_greater_than(0.1)\nresult = check.run(test_ds, model)\nresult.show(show_additional_outputs=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}