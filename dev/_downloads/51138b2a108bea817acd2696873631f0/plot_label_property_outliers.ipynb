{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Label Property Outliers {#plot_vision_label_property_outliers}\n=======================\n\nThis notebooks provides an overview for using and understanding the\nlabel property outliers check, used to detect outliers in simple label\nproperties in a dataset.\n\n**Structure:**\n\n-   [Why Check for Label Outliers?](#why-check-for-label-outliers)\n-   [How Does the Check Work?](#how-does-the-check-work)\n-   [Which Label Properties Are Used?](#which-label-properties-are-used)\n-   [Run the Check](#run-the-check)\n\nWhy Check for Label Outliers?\n-----------------------------\n\nExamining outliers may help you gain insights that you couldn\\'t have\nreached from taking an aggregate look or by inspecting random samples.\nFor example, it may help you understand you have some corrupt samples\n(e.g. a bounding box with area 0), or samples you didn\\'t expect to have\n(e.g. extreme aspect ratio). In some cases, these outliers may help\ndebug some performance discrepancies (the model can be excused for\nfailing on a zero size bounding box). In more extreme cases, the outlier\nsamples may indicate the presence of samples interfering with the\nmodel\\'s training by teaching the model to fit \\\"irrelevant\\\" samples.\n\nHow Does the Check Work?\n------------------------\n\nIn order to find outlier labels we use label properties (such as number\nof bounding boxes, bounding box area, etc.)\n\nWe use [Interquartile\nRange](https://en.wikipedia.org/wiki/Interquartile_range#Outliers) to\ndefine our upper and lower limit for the properties\\' values.\n\n### Which Label Properties Are Used?\n\nFor object detection we have default built-in label properties. For\nother tasks you have to define your own custom label properties. For the\nlist of the built-in object detection label properties and explanation\nabout custom properties refer to\n`vision properties </user-guide/vision/vision_properties>`{.interpreted-text\nrole=\"doc\"}.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the Check\n=============\n\nFor the example we will load COCO object detection data, and will run\nthe check with the default properties.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.checks import LabelPropertyOutliers\nfrom deepchecks.vision.datasets.detection.coco import load_dataset\n\ntrain_data = load_dataset(train=True, object_type='VisionData')\ncheck = LabelPropertyOutliers()\nresult = check.run(train_data)\nresult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To display the results in an IDE like PyCharm, you can use the following\ncode:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#  result.show_in_window()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result will be displayed in a new window.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe Graphic Result\n======================\n\nThe check displays a section for each property. In each section we show\nthe number of outliers and the non-outlier property range, and also the\nimages with the lowest and highest values for the property. In addition,\nif the property returns a value per bounding box, we then show only the\nrelevant bounding box which resulted in the outlier result.\n\nFor example in property \\\"Bounding Box Area (in pixels)\\\" we can see\nthat 80 outliers were found. Now we can inspect the samples and decide\nif we wish to ignore these kinds of samples or if we would like the\nmodel to be able to support them, in which case we may take a close look\ninto the model\\'s predictions on these samples.\n\nObserve Result Value\n====================\n\nThe check returns CheckResult object with a property \\'value\\' on it\nwhich contain the information that was calculated in the check\\'s run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result.value"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}