{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Robustness Report\n=================\n\nThis notebooks provides an overview for using and understanding\nrobustness report check.\n\n**Structure:**\n\n-   [How Does the RobustnessReport Check\n    Work?](#how-does-the-robustnessreport-check-work)\n-   [What Are Image Augmentations?](#what-are-image-augmentations)\n-   [Check requirements](#check-requirements)\n-   [Generate data and model](#generate-data-and-model)\n-   [Run the check](#run-the-check)\n-   [Define a condition](#define-a-condition)\n\nHow Does the RobustnessReport Check Work?\n-----------------------------------------\n\nThis check performs augmentations on images in the dataset, and measures\nthe change in model performance for each augmentation. This is done in\norder to estimate how well the model generalizes on the data.\n\nWhat Are Image Augmentations?\n-----------------------------\n\nAugmentations on images are any transformation done on the image, such\nas changing brightness and scale. The are used during model training for\n2 reasons:\n\n-   Data in training set is limited, and there\\'s a need to give the\n    model more data samples to learn on, especially ones with\n    augmentations that don\\'t necessarily exist in training dataset but\n    may be encountered in out-of-sample data.\n-   As the model relearns the same images again and again in each epoch,\n    augmentations on data are done in order to force the model to learn\n    a more generalized version of the image, so it will not overfit on\n    specific images.\n\n### If Performance Decreases Significantly on Augmented Images, This Could Mean That:\n\n-   Training dataset was not diverse enough for the model to learn its\n    features in a generalized way.\n-   Augmentations on train dataset were either not performed, or not\n    done enough.\n\n### When Is It Ok That the Model Will Decrease Performance Due to Augmentations?\n\n-   If out-of-sample data is not expected to be augmented in these ways,\n    it may not be of concern that the model\\'s performance decreases.\n    However, this could still mean that the model does not generalize\n    well enough, and therefore can decrease in performance for other\n    types of data shift.\n-   If augmentations are too extreme, the image may be changed without\n    recognition. In this case, where the human eye or professional eye\n    cannot perform the needed task as well, it is expected that the\n    model will not be able to infer correctly as well.\n\nCheck requirements\n------------------\n\nThe augmentations are usually performed in the\n[Dataset.\\_\\_getitem\\_\\_]{.title-ref} method, using a transformations\nobject. In order to run the check we need to be able to add the\naugmentations as the first augmentation in the transforms function.\nTherefore you need to:\n\n1.  Define in [VisionData]{.title-ref} the name of your transformations\n    field. The default field name is \\\"transforms\\\"\n2.  Use either [imgaug]{.title-ref} or [Albumentations]{.title-ref}\n    libraries as the transformations mechanism.\n3.  For object detection: Use a single transformation object for both\n    the data and the labels (use \\\"transforms\\\" instead of\n    \\\"transform\\\" + \\\"target\\_transform\\\")\n\nDefault Augmentations\n---------------------\n\n  Image Type   Augmentation name\n  ------------ -------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n  Grayscale    [RandomBrightnessContrast](https://albumentations.ai/docs/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RandomBrightnessContrast)\n  Grayscale    [ShiftScaleRotate](https://albumentations.ai/docs/api_reference/augmentations/geometric/transforms/#albumentations.augmentations.geometric.transforms.ShiftScaleRotate)\n  RGB          [HueSaturationValue](https://albumentations.ai/docs/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.HueSaturationValue)\n  RGB          [RGBShift](https://albumentations.ai/docs/api_reference/augmentations/transforms/#albumentations.augmentations.transforms.RGBShift)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate data and model\n=======================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.datasets.classification.mnist import (load_dataset,\n                                                             load_model)\n\nmnist_dataloader_test = load_dataset(train=False, batch_size=1000, object_type='VisionData')\nmodel = load_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check\n=============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n\nfrom deepchecks.vision.checks import RobustnessReport\n\nresult = RobustnessReport().run(mnist_dataloader_test, model)\nresult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe the check's output\n==========================\n\nAs we see in the results, the check applied different augmentations on\nthe input data, and then compared the model\\'s performance on the\noriginal images vs the augmeneted images. We then compare the overall\nmetrics and also the metrics per class, and we can see the difference of\nthe worst degraded classes.\n\nAs a result value the check returns per augmentation the overall metrics\nwith their relative difference from the original metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a condition\n==================\n\nWe can define a condition that enforce our model\\'s performance is not\ndegrading by more than given percentage when the data is augmeneted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = RobustnessReport().add_condition_degradation_not_greater_than(0.05)\nresult = check.run(mnist_dataloader_test, model)\nresult.show(show_additional_outputs=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}