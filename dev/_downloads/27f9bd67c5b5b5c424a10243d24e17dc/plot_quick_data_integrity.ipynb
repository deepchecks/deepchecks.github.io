{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Integrity Suite Quickstart {#quick_data_integrity}\n===============================\n\nThe deepchecks integrity suite is relevant any time you have data that\nyou wish to validate: whether it\\'s on a fresh batch of data, or right\nbefore splitting it or using it for training. Here we\\'ll use the\navocado prices dataset\n(`deepchecks.tabular.datasets.regression.avocado`{.interpreted-text\nrole=\"mod\"}), to demonstrate how you can run the suite with only a few\nsimple lines of code, and see which kind of insights it can find.\n\n``` {.bash}\n# Before we start, if you don't have deepchecks installed yet, run:\nimport sys\n!{sys.executable} -m pip install deepchecks -U --quiet\n\n# or install using pip from your python environment\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load and Prepare Data\n=====================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular import datasets\n\n# load data\ndata = datasets.regression.avocado.load_data(data_format='DataFrame', as_train_test=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insert a few typical problems to dataset for demonstration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\ndef add_dirty_data(df):\n    # change strings\n    df.loc[df[df['type'] == 'organic'].sample(frac=0.18).index,'type'] = 'Organic'\n    df.loc[df[df['type'] == 'organic'].sample(frac=0.01).index,'type'] = 'ORGANIC'\n    # add duplicates\n    df = pd.concat([df, df.sample(frac=0.156)], axis=0, ignore_index=True)\n    # add column with single value\n    df['Is Ripe'] = True\n    return df\n\n\ndirty_df = add_dirty_data(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run Deepchecks for Data Integrity\n=================================\n\nCreate a Dataset Object\n-----------------------\n\nCreate a deepchecks Dataset, including the relevant metadata (label,\ndate, index, etc.). Check out\n`deepchecks.tabular.Dataset`{.interpreted-text role=\"class\"} to see all\nof the columns and types that can be declared.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular import Dataset\n\n# Categorical features can be heuristically inferred, however we\n# recommend to state them explicitly to avoid misclassification.\n\n# Metadata attributes are optional. Some checks will run only if specific attributes are declared.\n\nds = Dataset(dirty_df, cat_features= ['type'], datetime_name='Date', label= 'AveragePrice')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the Deepchecks Suite\n========================\n\nValidate your data with the\n`deepchecks.tabular.suites.data_integrity`{.interpreted-text\nrole=\"func\"} suite. It runs on a single dataset, so you can run it on\nany batch of data (e.g. train data, test data, a new batch of data that\nrecently arrived)\n\nCheck out the\n`when you should use <when_should_you_use_deepchecks>`{.interpreted-text\nrole=\"ref\"} deepchecks guide for some more info about the existing\nsuites and when to use them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.suites import data_integrity\n\n# Run Suite:\ninteg_suite = data_integrity()\nsuite_result = integ_suite.run(ds)\n# Note: the result can be saved as html using suite_result.save_as_html()\n# or exported to json using suite_result.to_json()\nsuite_result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can inspect the suite outputs and see that there are a few problems\nwe\\'d like to fix. We\\'ll now fix them and check that they\\'re resolved\nby re-running those specific checks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run a Single Check\n==================\n\nWe can run a single check on a dataset, and see the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.checks import IsSingleValue, DataDuplicates\n\n# first let's see how the check runs:\nIsSingleValue().run(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# we can also add a condition:\nsingle_value_with_condition = IsSingleValue().add_condition_not_single_value()\nresult = single_value_with_condition.run(ds)\nresult.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We can also inspect and use the result's value:\nresult.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let\\'s remove the single value column and rerun (notice that we\\'re\nusing directly the `data` attribute that stores the dataframe inside the\nDataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ds.data.drop('Is Ripe', axis=1, inplace=True)\nresult = single_value_with_condition.run(ds)\nresult.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Alternatively we can fix the dataframe directly, and create a new dataset.\n# Let's fix also the duplicate values:\ndirty_df.drop_duplicates(inplace=True)\ndirty_df.drop('Is Ripe', axis=1, inplace=True)\nds = Dataset(dirty_df, cat_features=['type'], datetime_name='Date', label='AveragePrice')\nresult = DataDuplicates().add_condition_ratio_less_or_equal(0).run(ds)\nresult.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rerun Suite on the Fixed Dataset\n================================\n\nFinally, we\\'ll choose to keep the \\\"organic\\\" multiple spellings as\nthey represent different sources. So we\\'ll customaize the suite by\nremoving the condition from it (or delete check completely).\nAlternatively - we can customize it by creating a new Suite with the\ndesired checks and conditions. See\n`/user-guide/general/customizations/examples/plot_create_a_custom_suite`{.interpreted-text\nrole=\"doc\"} for more info.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# let's inspect the suite's structure\ninteg_suite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# and remove the condition:\ninteg_suite[3].clean_conditions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can re-run the suite using:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "res = integ_suite.run(ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and all of the conditions will pass.\n\n*Note: the check we manipulated will still run as part of the Suite,\nhowever it won\\'t appear in the Conditions Summary since it no longer\nhas any conditions defined on it. You can still see its display results\nin the Additional Outputs section*\n\nFor more info about working with conditions, see the detailed\n`/user-guide/general/customizations/examples/plot_configure_check_conditions`{.interpreted-text\nrole=\"doc\"} guide.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}