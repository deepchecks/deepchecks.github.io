{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "New Labels\n==========\n\nThis notebooks provides an overview for using and understanding the New\nLabels check.\n\n**Structure:**\n\n-   [How the check works](#How-the-check-works)\n-   [Run the check](#run-the-check)\n-   [Define a condition](#define-a-condition)\n\nHow the check works \\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\--In this check we\ncount the frequency of each class id in the test set then check which of\nthem do not apper in the training set. Note that by default this check\nrun on a sample of the data set and so it is possible that class ids\nthat are rare in the train set will also be considered as new labels in\nthe test set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the Check\n=============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.datasets.detection import coco\nfrom deepchecks.vision.checks import NewLabels\n\ncoco_train = coco.load_dataset(train=True, object_type='VisionData', shuffle=False)\ncoco_test = coco.load_dataset(train=False, object_type='VisionData', shuffle=False)\n\nresult = NewLabels().run(coco_train, coco_test)\nresult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe the check's output \\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~ The\ncheck searches for new labels in the test set. The value output is a\ndictionary containing of appearances of each newly found class\\_id in\naddition to the total number of labels in the test set for comparison\npurposes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a condition\n==================\n\nThe check has a default condition which can be defined. The condition\nverifies that the ratio of new labels out of the total number of labels\nin the test set is smaller than a given threshold. If the check is run\nwith the default sampling mechanism we recommend on setting the\ncondition threshold to a small percentage instead of setting it to 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = NewLabels().add_condition_new_label_ratio_not_greater_than(0.05)\ncheck.run(coco_train, coco_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case the condition identified that a major portion of the test\nset labels do not appear in the training set.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}