{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Weak Segments Performance {#tabular__weak_segments_performance}\n=========================\n\nThis notebook provides an overview for using and understanding the weak\nsegment performance check.\n\n**Structure:**\n\n-   [What is the purpose of the\n    check?](#what-is-the-purpose-of-the-check)\n-   [Automatically detecting weak\n    segments](#automatically-detecting-weak-segments)\n-   [Generate data & model](#generate-data-model)\n-   [Run the check](#run-the-check)\n-   [Define a condition](#define-a-condition)\n\nWhat is the purpose of the check?\n---------------------------------\n\nThe check is designed to help you easily identify the model\\'s weakest\nsegments in the data provided. In addition, it enables to provide a\nsublist of the Dataset\\'s features, thus limiting the check to search in\ninteresting subspaces.\n\nAutomatically detecting weak segments\n-------------------------------------\n\nThe check contains several steps:\n\n1.  We calculate loss for each sample in the dataset using the provided\n    model via either log-loss or MSE according to the task type.\n2.  Select a subset of features for the weak segment search. This is\n    done by selecting the features with the highest feature importance\n    to the model provided (within the features selected for check, if\n    limited).\n3.  We train multiple simple tree based models, each one is trained\n    using exactly two features (out of the ones selected above) to\n    predict the per sample error calculated before.\n4.  We extract the corresponding data samples for each of the leaves in\n    each of the trees (data segments) and calculate the model\n    performance on them. For the weakest data segments detected we also\n    calculate the model\\'s performance on data segments surrounding\n    them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate data & model\n=====================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.datasets.classification.lending_club import (\n    load_data, load_fitted_model)\n\n_, test_ds = load_data()\nmodel = load_fitted_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check\n=============\n\nThe check has several key parameters (that are all optional) that affect\nthe behavior of the check and especially its output.\n\n`columns / ignore_columns`: Controls which columns should be searched\nfor weak segments. By default, a heuristic is used to determine which\ncolumns to use based solely on their feature importance.\n\n`alternative_scorer`: Determines the metric to be used as the\nperformance measurement of the model on different segments. It is\nimportant to select a metric that is relevant to the data domain and\ntask you are performing. By default, the check uses Neg RMSE for\nregression tasks and Accuracy for classification tasks. For additional\ninformation on scorers and how to use them see\n`Metrics Guide <metrics_user_guide>`{.interpreted-text role=\"ref\"}.\n\n`segment_minimum_size_ratio`: Determines the minimum size of segments\nthat are of interest. The check will return data segments that contain\nat least this fraction of the total data samples. It is recommended to\ntry different configurations of this parameter as larger segments can be\nof interest even the model performance on them is superior.\n\n`categorical_aggregation_threshold`: By default the check will combine\nrare categories into a single category called \\\"Other\\\". This parameter\ndetermines the frequency threshold for categories to be mapped into to\nthe \\\"other\\\" category.\n\n`multiple_segments_per_column`: If True, will allow the same feature to\nbe a segmenting feature in multiple segments, otherwise each feature can\nappear in one segment at most. True by default.\n\nsee\n`API reference <deepchecks.tabular.checks.model_evaluation.WeakSegmentsPerformance>`{.interpreted-text\nrole=\"class\"} for more details.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.checks import WeakSegmentsPerformance\nfrom sklearn.metrics import make_scorer, f1_score\n\nscorer = {'f1': make_scorer(f1_score, average='micro')}\ncheck = WeakSegmentsPerformance()\nresult = check.run(test_ds, model)\nresult.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe the check\\'s output\n===========================\n\nWe see in the results that the check indeed found several segments on\nwhich the model performance is below average. In the heatmap display we\ncan see model performance on the weakest segments and their environment\nwith respect to the two features that are relevant to the segment. We\ncan switch between several such segments using the tabs on the top. In\norder to get the full list of weak segments found we will inspect the\n`result.value` attribute. Shown below are the 3 segments with the worst\nperformance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result.value['weak_segments_list'].head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a condition\n==================\n\nWe can add a condition that will validate the model\\'s performance on\nthe weakest segment detected is above a certain threshold. A scenario\nwhere this can be useful is when we want to make sure that the model is\nnot under performing on a subset of the data that is of interest to us,\nfor example specific age or gender groups.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Let's add a condition and re-run the check:\n\ncheck = WeakSegmentsPerformance(alternative_scorer=scorer, segment_minimum_size_ratio=0.03)\ncheck.add_condition_segments_relative_performance_greater_than(0.1)\nresult = check.run(test_ds, model)\nresult.show(show_additional_outputs=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}