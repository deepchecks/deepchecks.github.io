{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Image Dataset Drift\n===================\n\nThis notebooks provides an overview for using and understanding the\nimage dataset drift check, used to detect drift in simple image\nproperties between train and test datasets.\n\n**Structure:**\n\n-   [What Is Dataset Drift?](#what-is-dataset-drift)\n-   [How Does the ImageDatasetDrift Check\n    Work?](#how-does-the-imagedatasetdrift-check-work)\n-   [Which Image Properties Are Used?](#which-image-properties-are-used)\n-   [Loading The Data](#loading-the-data)\n-   [Run The Check](#run-the-check)\n\nWhat Is Dataset Drift?\n----------------------\n\nData drift is simply a change in the distribution of data over time. It\nis also one of the top reasons that a machine learning model performance\ndegrades over time.\n\nSpecifically, a whole dataset drift, or a multivariate dataset drift,\noccurs when there is a change in the relation between input features.\n\nCauses of data drift include:\n\n-   Natural drift in the data, such as lighting (brightness) changes\n    between summer and winter.\n-   Upstream process changes, such as a camera being replaced that has a\n    different lens, which makes images sharper.\n-   Data quality issues, such as a malfunctioning camera that always\n    returns a black image.\n-   Data pipeline errors, such as a change in image augmentations done\n    in preprocessing.\n\nIn the context of machine learning, drift between the training set and\nthe test set (which is not due to augmentation) will likely make the\nmodel prone to errors. In other words, if the model was trained on data\nthat is different from the current test data, it will probably make more\nmistakes predicting the target variable.\n\nHow Does the ImageDatasetDrift Check Work?\n\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\\^\nThere are many methods to detect feature drift. Some of them are\nstatistical methods that aim to measure difference between distribution\nof 2 given sets. This methods are more suited to univariate\ndistributions and are primarily used to detect drift between 2 subsets\nof a single feature.\n\nMeasuring a multivariate data drift is a bit more challenging. In the\nimage dataset drift check, the multivariate drift is measured by\ntraining a classifier that detects which samples come from a known\ndistribution and defines the drift by the accuracy of this classifier.\n\nPractically, the check concatenates the train and the test sets, and\nassigns label 0 to samples that come from the training set, and 1 to\nthose from the test set. Then, we train a binary classifer of type\n[Histogram-based Gradient Boosting Classification\nTree](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html),\nand measure the drift score from the AUC score of this classifier.\n\nAs the classifier is a tree model, that cannot run on the images\nthemselves, the check calculates properties for each image (such as\nbrightness, aspect ratio etc.) and uses them as input features to the\nclassifier.\n\n### Which Image Properties Are Used?\n\n  Property name                   What is it\n  ------------------------------- ----------------------------------------------------------------------------------------------------------------------------------------\n  Aspect Ratio                    Ratio between height and width of image (height / width)\n  Area                            Area of image in pixels (height \\* width)\n  Brightness                      Average intensity of image pixels. Color channels have different weights according to RGB-to-Grayscale formula\n  RMS Contrast                    Contrast of image, calculated by standard deviation of pixels\n  Mean Red Relative Intensity     Mean over all pixels of the red channel, scaled to their relative intensity in comparison to the other channels \\[r / (r + g + b)\\].\n  Mean Green Relative Intensity   Mean over all pixels of the green channel, scaled to their relative intensity in comparison to the other channels \\[g / (r + g + b)\\].\n  Mean Blue Relative Intensity    Mean over all pixels of the blue channel, scaled to their relative intensity in comparison to the other channels \\[b / (r + g + b)\\].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imports\n=======\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom deepchecks.vision.checks import ImageDatasetDrift\nfrom deepchecks.vision.datasets.detection.coco import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading the data\n================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_ds = load_dataset(train=True, object_type='VisionData')\ntest_ds = load_dataset(train=False, object_type='VisionData')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check\n=============\n\nwithout drift\n-------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = ImageDatasetDrift()\ncheck.run(train_dataset=train_ds, test_dataset=test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insert drift\n============\n\nNow, we will define a custom data object that will insert a drift to the\ntraining set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.datasets.detection.coco import COCOData\n\n\ndef add_brightness(img):\n    reverse = 255 - img\n    addition_of_brightness = (reverse * 0.07).astype(int)\n    return img + addition_of_brightness\n\n\nclass DriftedCOCO(COCOData):\n    \n    def batch_to_images(self, batch):\n        return [add_brightness(np.array(img)) for img in batch[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_dataloader = load_dataset(train=True, object_type='DataLoader')\ntest_dataloader = load_dataset(train=False, object_type='DataLoader')\n\ndrifted_train_ds = DriftedCOCO(train_dataloader)\ntest_ds = COCOData(test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check again\n===================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = ImageDatasetDrift()\ncheck.run(train_dataset=drifted_train_ds, test_dataset=test_ds)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}