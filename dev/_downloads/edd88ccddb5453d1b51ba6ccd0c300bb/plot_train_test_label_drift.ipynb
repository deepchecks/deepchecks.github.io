{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train Test Label Drift {#plot_vision_train_test_label_drift}\n======================\n\nThis notebooks provides an overview for using and understanding label\ndrift check.\n\n**Structure:**\n\n-   [What Is Label Drift?](#what-is-label-drift)\n-   [Which Label Properties Are Used?](#which-label-properties-are-used)\n-   [Run check on a Classification\n    task](#run-the-check-on-a-classification-task-mnist)\n-   [Run check on an Object Detection\n    task](#run-the-check-on-an-object-detection-task-coco)\n\nWhat Is Label Drift?\n--------------------\n\nDrift is simply a change in the distribution of data over time, and it\nis also one of the top reasons why machine learning model\\'s performance\ndegrades over time.\n\nLabel drift is when drift occurs in the label itself.\n\nFor more information on drift, please visit our\n`drift guide </user-guide/general/drift_guide>`{.interpreted-text\nrole=\"doc\"}.\n\n### How Deepchecks Detects Label Drift\n\nThis check detects label drift by using\n`univariate measures <drift_detection_by_univariate_measure>`{.interpreted-text\nrole=\"ref\"} on the label properties.\n\n### Using Label Properties to Detect Label Drift\n\nIn computer vision specifically, our labels may be complex, and\nmeasuring their drift is not a straightforward task. Therefore, we\ncalculate drift on different\n`properties of the label</user-guide/vision/vision_properties>`{.interpreted-text\nrole=\"doc\"}, on which we can directly measure drift.\n\n#### Which Label Properties Are Used?\n\n  Task Type          Property name                        What is it\n  ------------------ ------------------------------------ ----------------------------------------------\n  Classification     Samples Per Class                    Number of images per class\n  Object Detection   Samples Per Class                    Number of bounding boxes per class\n  Object Detection   Bounding Box Area                    Area of bounding box (height \\* width)\n  Object Detection   Number of Bounding Boxes Per Image   Number of bounding box objects in each image\n\nRun the check on a Classification task (MNIST)\n----------------------------------------------\n\n### Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.checks import TrainTestLabelDrift\nfrom deepchecks.vision.datasets.classification.mnist import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading Data\n============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_ds = load_dataset(train=True, batch_size=64, object_type='VisionData')\ntest_ds = load_dataset(train=False, batch_size=1000, object_type='VisionData')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running TrainTestLabelDrift on classification\n=============================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = TrainTestLabelDrift()\nresult = check.run(train_ds, test_ds)\nresult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Understanding the results\n=========================\n\nWe can see there is almost no drift between the train & test labels.\nThis means the split to train and test was good (as it is balanced and\nrandom). Let\\'s check the performance of a simple model trained on\nMNIST.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.checks import ClassPerformance\nfrom deepchecks.vision.datasets.classification.mnist import \\\n    load_model as load_mnist_model\n\nmnist_model = load_mnist_model(pretrained=True)\nClassPerformance().run(train_ds, test_ds, mnist_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To display the results in an IDE like PyCharm, you can use the following\ncode:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#  ClassPerformance().run(train_ds, test_ds, mnist_model).show_in_window()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result will be displayed in a new window.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MNIST with label drift\n======================\n\nNow, let\\'s try to separate the MNIST dataset in a different manner that\nwill result in a label drift, and see how it affects the performance. We\nare going to create a custom [collate\\_fn]{.title-ref}\\` in the test\ndataset, that will select samples with class 0 in a 1/10 chances.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\nmnist_dataloader_train = load_dataset(train=True, batch_size=64, object_type='DataLoader')\nmnist_dataloader_test = load_dataset(train=False, batch_size=1000, object_type='DataLoader')\nfull_mnist = torch.utils.data.ConcatDataset([mnist_dataloader_train.dataset, mnist_dataloader_test.dataset])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_dataset, test_dataset = torch.utils.data.random_split(full_mnist, [60000,10000], generator=torch.Generator().manual_seed(42))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inserting drift to the test set\n===============================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom torch.utils.data._utils.collate import default_collate\n\nnp.random.seed(42)\n\n\ndef collate_test(batch):\n    modified_batch = []\n    for item in batch:\n        image, label = item\n        if label == 0:\n            if np.random.randint(5) == 0:\n                modified_batch.append(item)\n            else:\n                modified_batch.append((image, 1))\n        else:\n            modified_batch.append(item)\n\n    return default_collate(modified_batch)\n\n\nmod_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64)\nmod_test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, collate_fn=collate_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.datasets.classification.mnist import MNISTData\n\nmod_train_ds = MNISTData(mod_train_loader)\nmod_test_ds = MNISTData(mod_test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check\n=============\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = TrainTestLabelDrift()\ncheck.run(mod_train_ds, mod_test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add a condition\n===============\n\nWe could also add a condition to the check to alert us to changes in the\nlabel distribution, such as the one that occurred here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = TrainTestLabelDrift().add_condition_drift_score_less_than()\ncheck.run(mod_train_ds, mod_test_ds)\n\n# As we can see, the condition alerts us to the present of drift in the label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results\n=======\n\nWe can see the check successfully detects the (expected) drift in class\n0 distribution between the train and test sets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But how does this affect the performance of the model?\n======================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ClassPerformance().run(mod_train_ds, mod_test_ds, mnist_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inferring the results\n=====================\n\nWe can see the drop in the precision of class 0, which was caused by the\nclass imbalance indicated earlier by the label drift check.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check on an Object Detection task (COCO)\n================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.datasets.detection.coco import load_dataset\n\ntrain_ds = load_dataset(train=True, object_type='VisionData')\ntest_ds = load_dataset(train=False, object_type='VisionData')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = TrainTestLabelDrift()\ncheck.run(train_ds, test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Label drift is detected!\n========================\n\nWe can see that the COCO128 contains a drift in the out of the box\ndataset. In addition to the label count per class, the label drift check\nfor object detection tasks include drift calculation on certain\nmeasurements, like the bounding box area and the number of bboxes per\nimage.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}