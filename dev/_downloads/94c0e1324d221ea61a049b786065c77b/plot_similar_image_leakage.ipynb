{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similar Image Leakage {#plot_vision_similar_image_leakage}\n=====================\n\nThis notebook provides an overview for using and understanding the\n\\\"Similar Image Leakage\\\" check.\n\n**Structure:**\n\n-   [What is the purpose of the\n    check?](#what-is-the-purpose-of-the-check)\n-   [Run the check](#run-the-check)\n-   [Define a condition](#define-a-condition)\n\nWhat is the purpose of the check?\n---------------------------------\n\nThe check helps identify if the training dataset contains any images\nthat are similar to any images in the test dataset. Such a situation is\nnearly always a case of leakage, because we can expect that the model\nwill have an easier time getting correct predictions on an image that is\nsimilar to an image in the training set, compared to it\\'s \\\"real\nworld\\\" performance. This may mean that the metrics we\\'re seeing for\nthe test data are too optimistic, and we should remove those similar\nimages from the test set.\n\n### How is similarity calculated?\n\nThe similarity is calculated using an image hash known as Average Hash.\nThis hash compresses the image using the following algorithm:\n\n1.  Resize the image to a very compact form (the check default is 8X8).\n2.  Compute the average of the image pixels.\n3.  For each pixel, replace value by the boolean result of\n    [pixel\\_value \\>= image\\_average]{.title-ref}.\n\nNow we end up with a representation of the image that is 8 bytes long,\nbut still contains some real information about the image content.\n\nWe then proceed to check for similar images by searching for test images\nwhose hash is close to a hash of a training image, when distance is\ndefined by the Hamming distance between the binary vectors that are the\nhashed images.\n\n### Note about default parameters\n\nSimilarity between images depends on the purpose of the dataset. This is\nbecause sometimes we\\'re training a model to find large differences\nbetween images (e.g. people vs dogs) and sometimes we\\'re training to\nfind small differences (e.g. different types of trees). Moreover,\nsometimes our images are taken from real-world datasets, where they were\ntaken by different people, in different locations. In some use-cases\nthough the images are \\\"cleaner\\\", such as ones taken under microscope\nor from the same security camera with the same background.\n\nThe check\\'s default parameters are set to match a real-world rgb photos\nand their differences. If your dataset has more delicate differences in\nit, it is advised to use the *hash\\_size* and *similarity\\_threshold*\nparameters of this check. The *hash\\_size* parameter controls the size\nof the hashed image. A larger hash\\_size will enable to find finer\ndifferences between images (and results in less similarity). The\n*similarity\\_threshold* parameter controls the ratio of pixels that need\nto be different in order for 2 images to be considered \\\"different\\\". A\nlower similarity\\_threshold will define less images as \\\"similar\\\".\n\nRun the check\n-------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.vision.checks import SimilarImageLeakage\nfrom deepchecks.vision.datasets.detection.coco import load_dataset\n\ntrain_ds = load_dataset(train=True, object_type='VisionData', shuffle=False)\ntest_ds = load_dataset(train=False, object_type='VisionData', shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = SimilarImageLeakage()\nresult = check.run(train_ds, test_ds)\nresult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To display the results in an IDE like PyCharm, you can use the following\ncode:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#  result.show_in_window()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result will be displayed in a new window.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, no similar images were found.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insert training images into test\n================================\n\nLet\\'s now see what happens when we insert some of the training images\ninto the test set. We\\'ll insert them with some changes to brightness to\nsee what happens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from copy import copy\n\nimport numpy as np\nfrom PIL import Image\n\nfrom deepchecks.vision.utils.test_utils import get_modified_dataloader\n\ntest_ds_modified = copy(test_ds)\n\ndef get_modification_func():\n    other_dataset = train_ds.data_loader.dataset\n\n    def mod_func(orig_dataset, idx):\n        if idx in range(5):\n            # Run only on the first 5 images\n            data, label = other_dataset[idx]\n            # Add some brightness by adding 50 to all pixels\n            return Image.fromarray(np.clip(np.array(data, dtype=np.uint16) + 50, 0, 255).astype(np.uint8)), label\n        else:\n            return orig_dataset[idx]\n\n    return mod_func\n\n\ntest_ds_modified._data_loader = get_modified_dataloader(test_ds, get_modification_func())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Re-run after introducing the similar images\n===========================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = SimilarImageLeakage()\nresult = check.run(train_ds, test_ds_modified)\nresult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the check detected the five images from the training set\nwe introduced to the test set.\n\nDefine a condition\n==================\n\nWe can define on our check a condition that will validate no similar\nimages where found. The default is that no similar images are allowed at\nall, but this can be modified as shown here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = SimilarImageLeakage().add_condition_similar_images_less_or_equal(3)\nresult = check.run(train_dataset=train_ds, test_dataset=test_ds_modified)\nresult.show(show_additional_outputs=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}