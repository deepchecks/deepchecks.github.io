
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "tutorials/tabular/examples/plot_add_a_custom_check.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_tutorials_tabular_examples_plot_add_a_custom_check.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_tutorials_tabular_examples_plot_add_a_custom_check.py:


Add a Custom Check
******************

It is possible to extend deepchecks by implementing custom checks. This
enables you to have your own logic of metrics or validation, or even just
to display your own graph using deepchecks' suite.

* `Check Structure <#check-structure>`__
* `Write a Basic Check <#write-a-basic-check>`__
* `Check Display <#check-display>`__

Check Structure
===============
Each check consists of 3 main parts:

* Return Value
* Display
* Conditions

This guide will demonstrate how to implement a Check with a return value and
display, for addding a condition see working with conditions (LINK)

Write a Basic Check
===================
Let's implement a check for comparing the sizes of the test and the train datasets.

The first step is to create check class, which inherits from a base check class.
Each base check is differed by its run method signature, read more about all
`types <#base-checks-types>`__. In this case we will use ``TrainTestBaseCheck``,
which is used to compare between the test and the train datasets. After
creating the basic class with the run_logic function we will write our check
logic inside it.

*Good to know: the return value of a check can be any object, a number,
dictionary, string, etc...*

.. GENERATED FROM PYTHON SOURCE LINES 41-58

.. code-block:: default


    from deepchecks.tabular import TrainTestCheck, Dataset, Context
    from deepchecks.core import CheckResult


    class DatasetSizeComparison(TrainTestCheck):
        """Check which compares the sizes of train and test datasets."""
    
        def run_logic(self, context: Context) -> CheckResult:
            ## Check logic
            train_size = context.train.n_samples
            test_size = context.test.n_samples
        
            ## Return value as check result
            return_value = {'train_size': train_size, 'test_size': test_size}
            return CheckResult(return_value)








.. GENERATED FROM PYTHON SOURCE LINES 59-60

Hooray! we just implemented a custom check. Now let's create two Datasets and try to run it:

.. GENERATED FROM PYTHON SOURCE LINES 60-70

.. code-block:: default


    import pandas as pd

    # We'll use dummy data for the purpose of this demonstration
    train_dataset = Dataset(pd.DataFrame(data={'x': [1,2,3,4,5,6,7,8,9]}), label=None)
    test_dataset = Dataset(pd.DataFrame(data={'x': [1,2,3]}), label=None)

    result = DatasetSizeComparison().run(train_dataset, test_dataset)
    result






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>IPyWidget export</title>
    </head>
    <body>

    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed.js" crossorigin="anonymous"></script>
    <script type="application/vnd.jupyter.widget-state+json">
    {
      "version_major": 2,
      "version_minor": 0,
      "state": {
        "f0333209f55e4331b6c0dc541dd44b7c": {
          "model_name": "VBoxModel",
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "children": [
              "IPY_MODEL_7837fe25e59c42c7b03771bedd5502e0"
            ],
            "layout": "IPY_MODEL_04cd9e8eb351411ba5bb3a88961f577d"
          }
        },
        "7837fe25e59c42c7b03771bedd5502e0": {
          "model_name": "HTMLModel",
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "layout": "IPY_MODEL_9a39f92d74e14872af28c10446e4514a",
            "style": "IPY_MODEL_20389bd7677149f98221e048d958d0dc",
            "value": "<h4>Dataset Size Comparison</h4><p>Check which compares the sizes of train and test datasets.</p><h5>Additional Outputs</h5><p><b>&#x2713;</b> Nothing found</p>"
          }
        },
        "9a39f92d74e14872af28c10446e4514a": {
          "model_name": "LayoutModel",
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "state": {}
        },
        "20389bd7677149f98221e048d958d0dc": {
          "model_name": "DescriptionStyleModel",
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "state": {}
        },
        "04cd9e8eb351411ba5bb3a88961f577d": {
          "model_name": "LayoutModel",
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "state": {}
        }
      }
    }
    </script>
    <script type="application/vnd.jupyter.widget-view+json">
    {"version_major": 2, "version_minor": 0, "model_id": "f0333209f55e4331b6c0dc541dd44b7c"}
    </script>

    </body>
    </html>

    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 71-75

Our check ran successfully but we got the print "Nothing found". This is
because we haven't defined to the check anything to display, so the default
behavior is to print "Nothing found". In order to access the value that
we have defined earlier we can use the "value" property on the result.

.. GENERATED FROM PYTHON SOURCE LINES 77-80

.. code-block:: default


    result.value





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    {'train_size': 9, 'test_size': 3}



.. GENERATED FROM PYTHON SOURCE LINES 81-83

To see code references for more complex checks (that can receive parameters
etc.), check out any of your favorite checks from our API Reference (LINK).

.. GENERATED FROM PYTHON SOURCE LINES 85-96

Check Display
=============
Most of the times we will want our checks to have a visual display that will
quickly summarize the check result. We can pass objects for display to the
``CheckResult``. Objects for display should be of type: html string, dataframe
or a function that plots a graph. Let's define a graph that will be displayed using
``matplotlib``. In order to use ``matplotlib`` we have to implement the code
inside a function and not call it directly in the check, this is due to
architectural limitations of ``matplotlib``.

*Good to know: ``display`` can receive a single object to display or a list of objects*

.. GENERATED FROM PYTHON SOURCE LINES 96-122

.. code-block:: default


    from deepchecks.tabular import Dataset, TrainTestCheck, Context
    from deepchecks.core import CheckResult
    import matplotlib.pyplot as plt

    class DatasetSizeComparison(TrainTestCheck):
        """Check which compares the sizes of train and test datasets."""
    
        def run_logic(self, context: Context) -> CheckResult:
            ## Check logic
            train_size = context.train.n_samples
            test_size = context.test.n_samples
        
            ## Create the check result value
            sizes = {'Train': train_size, 'Test': test_size}
            sizes_df_for_display =  pd.DataFrame(sizes, index=['Size'])
        
            ## Display function of matplotlib graph:
            def graph_display():
                plt.bar(sizes.keys(), sizes.values(), color='green')
                plt.xlabel("Dataset")
                plt.ylabel("Size")
                plt.title("Datasets Size Comparison")
        
            return CheckResult(sizes, display=[sizes_df_for_display, graph_display])








.. GENERATED FROM PYTHON SOURCE LINES 123-124

Let us check it out

.. GENERATED FROM PYTHON SOURCE LINES 124-127

.. code-block:: default


    DatasetSizeComparison().run(train_dataset, test_dataset)






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>IPyWidget export</title>
    </head>
    <body>

    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed.js" crossorigin="anonymous"></script>
    <script type="application/vnd.jupyter.widget-state+json">
    {
      "version_major": 2,
      "version_minor": 0,
      "state": {
        "7be8b93044db41959cd1a9ec65603534": {
          "model_name": "VBoxModel",
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "children": [
              "IPY_MODEL_6c6eaa0269574b468cd74b6f6b82bdf5",
              "IPY_MODEL_dd3310e266ce4617b3364f0108a9e656",
              "IPY_MODEL_1584702555e84560952d7c1e2c5560ab"
            ],
            "layout": "IPY_MODEL_bc93ecba02e54d00880d516caee021fa"
          }
        },
        "6c6eaa0269574b468cd74b6f6b82bdf5": {
          "model_name": "HTMLModel",
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "layout": "IPY_MODEL_9c1738f788ad4e949972fe908cb7db19",
            "style": "IPY_MODEL_ea7f78a0cdf64bc5a77b13d6985a67e7",
            "value": "<h4>Dataset Size Comparison</h4><p>Check which compares the sizes of train and test datasets.</p><h5>Additional Outputs</h5><style type=\"text/css\">\n#T_c1084 table {\n  text-align: left;\n  white-space: pre-wrap;\n}\n#T_c1084 thead {\n  text-align: left;\n  white-space: pre-wrap;\n}\n#T_c1084 tbody {\n  text-align: left;\n  white-space: pre-wrap;\n}\n#T_c1084 th {\n  text-align: left;\n  white-space: pre-wrap;\n}\n#T_c1084 td {\n  text-align: left;\n  white-space: pre-wrap;\n}\n</style>\n<table id=\"T_c1084\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_c1084_level0_col0\" class=\"col_heading level0 col0\" >Train</th>\n      <th id=\"T_c1084_level0_col1\" class=\"col_heading level0 col1\" >Test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_c1084_level0_row0\" class=\"row_heading level0 row0\" >Size</th>\n      <td id=\"T_c1084_row0_col0\" class=\"data row0 col0\" >9</td>\n      <td id=\"T_c1084_row0_col1\" class=\"data row0 col1\" >3</td>\n    </tr>\n  </tbody>\n</table>\n"
          }
        },
        "9c1738f788ad4e949972fe908cb7db19": {
          "model_name": "LayoutModel",
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "state": {}
        },
        "ea7f78a0cdf64bc5a77b13d6985a67e7": {
          "model_name": "DescriptionStyleModel",
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "state": {}
        },
        "dd3310e266ce4617b3364f0108a9e656": {
          "model_name": "OutputModel",
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "layout": "IPY_MODEL_09717fd956934b95b17dcbe08f80847f",
            "outputs": []
          }
        },
        "09717fd956934b95b17dcbe08f80847f": {
          "model_name": "LayoutModel",
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "state": {}
        },
        "1584702555e84560952d7c1e2c5560ab": {
          "model_name": "HTMLModel",
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "layout": "IPY_MODEL_2c6eb4bf58ca4aa590d47889f3ad1697",
            "style": "IPY_MODEL_4657a5b8e31b4a03a6c0ee88ab2e18af"
          }
        },
        "2c6eb4bf58ca4aa590d47889f3ad1697": {
          "model_name": "LayoutModel",
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "state": {}
        },
        "4657a5b8e31b4a03a6c0ee88ab2e18af": {
          "model_name": "DescriptionStyleModel",
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "state": {}
        },
        "bc93ecba02e54d00880d516caee021fa": {
          "model_name": "LayoutModel",
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "state": {}
        }
      }
    }
    </script>
    <script type="application/vnd.jupyter.widget-view+json">
    {"version_major": 2, "version_minor": 0, "model_id": "7be8b93044db41959cd1a9ec65603534"}
    </script>

    </body>
    </html>

    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 128-152

Voila!
------
Now we have a check that prints a graph and has a value. We can add this
check to any Suite and it will run within it.

The next possible step is to implement a condition, which will allow us
to give the check result a pass / fail mark. To do so, check out the
following guide (LINK)

Base Checks Types
-----------------
There are a number of different ``BaseCheck`` Classes to inherit from.
Each base check is differed by the objects it requires in order to run,
and their sole difference is the ``run`` method's signature.

+---------------------------+-------------------------------------------------------+------------------------------------------------------------------------------------------------------+
| Check                     | ``run`` Signature                                     | Notes                                                                                                |
+===========================+=======================================================+======================================================================================================+
|``SingleDatasetBaseCheck`` |``run(self, dataset, model=None)``                     | When used in a suite you can choose whether to run on the test dataset, the train dataset or on both |
+---------------------------+-------------------------------------------------------+------------------------------------------------------------------------------------------------------+
|``TrainTestBaseCheck``     |``run(self, train_dataset, test_dataset, model=None)`` |                                                                                                      |
+---------------------------+-------------------------------------------------------+------------------------------------------------------------------------------------------------------+
|``ModelOnlyBaseCheck``     |``run(self, model)``                                   |                                                                                                      |
+---------------------------+-------------------------------------------------------+------------------------------------------------------------------------------------------------------+


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.052 seconds)


.. _sphx_glr_download_tutorials_tabular_examples_plot_add_a_custom_check.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_add_a_custom_check.py <plot_add_a_custom_check.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_add_a_custom_check.ipynb <plot_add_a_custom_check.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
