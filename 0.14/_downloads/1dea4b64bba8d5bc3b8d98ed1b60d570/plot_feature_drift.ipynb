{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feature Drift {#tabular__feature_drift}\n=============\n\nThis notebooks provides an overview for using and understanding feature\ndrift check.\n\n**Structure:**\n\n-   [What is a feature drift?](#what-is-a-feature-drift)\n-   [Generate data & model](#generate-data-model)\n-   [Run the check](#run-the-check)\n-   [Define a condition](#define-a-condition)\n-   [Get an aggregated value](#get-an-aggregated-value)\n\nWhat is a feature drift?\n------------------------\n\nDrift is simply a change in the distribution of data over time, and it\nis also one of the top reasons why machine learning model\\'s performance\ndegrades over time.\n\nFeature drift is a data drift that occurs in a single feature in the\ndataset.\n\nFor more information on drift, please visit our\n`Drift Guide <drift_user_guide>`{.interpreted-text role=\"ref\"}.\n\n### How Deepchecks Detects Feature Drift\n\nThis check detects feature drift by using\n`univariate measures <drift_detection_by_univariate_measure>`{.interpreted-text\nrole=\"ref\"} on each feature column separately. Another possible method\nfor drift detection is by\n`a domain classifier <drift_detection_by_domain_classifier>`{.interpreted-text\nrole=\"ref\"} which is used in the\n`Multivariate Drift check <tabular__multivariate_drift>`{.interpreted-text\nrole=\"ref\"}.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate data & model\n=====================\n\nLet\\'s generate a mock dataset of 2 categorical and 2 numerical features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\n\nnp.random.seed(42)\n\ntrain_data = np.concatenate([np.random.randn(1000,2), np.random.choice(a=['apple', 'orange', 'banana'], p=[0.5, 0.3, 0.2], size=(1000, 2))], axis=1)\ntest_data = np.concatenate([np.random.randn(1000,2), np.random.choice(a=['apple', 'orange', 'banana'], p=[0.5, 0.3, 0.2], size=(1000, 2))], axis=1)\n\ndf_train = pd.DataFrame(train_data, columns=['numeric_without_drift', 'numeric_with_drift', 'categorical_without_drift', 'categorical_with_drift'])\ndf_test = pd.DataFrame(test_data, columns=df_train.columns)\n\ndf_train = df_train.astype({'numeric_without_drift': 'float', 'numeric_with_drift': 'float'})\ndf_test = df_test.astype({'numeric_without_drift': 'float', 'numeric_with_drift': 'float'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insert drift into test:\n=======================\n\nNow, we insert a synthetic drift into 2 columns in the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df_test['numeric_with_drift'] = df_test['numeric_with_drift'].astype('float') + abs(np.random.randn(1000)) + np.arange(0, 1, 0.001) * 4\ndf_test['categorical_with_drift'] = np.random.choice(a=['apple', 'orange', 'banana', 'lemon'], p=[0.5, 0.25, 0.15, 0.1], size=(1000, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training a model\n================\n\nNow, we are building a dummy model (the label is just a random numerical\ncolumn). We preprocess our synthetic dataset so categorical features are\nbeing encoded with an OrdinalEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom deepchecks.tabular import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n    ('handle_cat', ColumnTransformer(\n        transformers=[\n            ('num', 'passthrough',\n             ['numeric_with_drift', 'numeric_without_drift']),\n            ('cat',\n             Pipeline([\n                 ('encode', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n             ]),\n             ['categorical_with_drift', 'categorical_without_drift'])\n        ]\n    )),\n    ('model', DecisionTreeClassifier(random_state=0, max_depth=2))]\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "label = np.random.randint(0, 2, size=(df_train.shape[0],))\ncat_features = ['categorical_without_drift', 'categorical_with_drift']\ndf_train['target'] = label\ntrain_dataset = Dataset(df_train, label='target', cat_features=cat_features)\n\nmodel.fit(train_dataset.data[train_dataset.features], label)\n\nlabel = np.random.randint(0, 2, size=(df_test.shape[0],))\ndf_test['target'] = label\ntest_dataset = Dataset(df_test, label='target', cat_features=cat_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check\n=============\n\nLet\\'s run deepchecks\\' feature drift check and see the results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.tabular.checks import FeatureDrift\n\ncheck = FeatureDrift()\nresult = check.run(train_dataset=train_dataset, test_dataset=test_dataset, model=model)\nresult.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe the check\\'s output\n===========================\n\nAs we see from the results, the check detects and returns the drift\nscore per feature. As we expect, the features that were manually\nmanipulated to contain a strong drift in them were detected.\n\nIn addition to the graphs, each check returns a value that can be\ncontrolled in order to define expectations on that value (for example,\nto define that the drift score for every feature must be below 0.05).\n\nLet\\'s see the result value for our check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result.value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a condition\n==================\n\nAs we can see, we get the drift score for each feature in the dataset,\nalong with the feature importance in respect to the model.\n\nNow, we define a condition that enforce each feature\\'s drift score must\nbe below 0.1. A condition is deepchecks\\' way to enforce that results\nare OK, and we don\\'t have a problem in our data or model!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check_cond = check.add_condition_drift_score_less_than(max_allowed_categorical_score=0.2,\n                                                       max_allowed_numeric_score=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result = check_cond.run(train_dataset=train_dataset, test_dataset=test_dataset)\nresult.show(show_additional_outputs=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we see, our condition successfully detects and filters the\nproblematic features that contains a drift!\n\nGet an aggregated value\n=======================\n\nUsing the\n`reduce_output <deepchecks.tabular.checks.train_test_validation.FeatureDrift.reduce_output>`{.interpreted-text\nrole=\"func\"} function we can combine the drift values per feature and\nget a collective score that reflects the effect of the drift on the\nmodel, taking into account all the features. In scenarios where labels\nare unavailable (either temporarily of permanently) this value can be a\ngood indicator of possible deterioration in the model\\'s performance.\n\nWe can define the type of aggregation we want to use via the\n[aggregation\\_method]{.title-ref} parameter. The possible values are:\n\n`l3_weighted`: Default. L3 norm over the \\'per-feature scores\\' vector\nweighted by the feature importance, specifically, sum(FI \\*\nPER\\_FEATURE\\_SCORES\\^3)\\^(1/3). This method takes into account the\nfeature importance yet puts more weight on the per-feature scores. This\nmethod is recommended for most cases.\n\n`l5_weighted`: Similar to \\'l3\\_weighted\\', but with L5 norm. Puts even\nmore emphasis on the per-feature scores and specifically on the largest\nper-feature scores returning a score closer to the maximum among the\nper-feature scores.\n\n`weighted`: Weighted mean of per-feature scores based on feature\nimportance.\n\n`max`: Maximum of all the per-feature scores.\n\n`none`: No averaging. Return a dict with a per-feature score for each\nfeature.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "check = FeatureDrift(aggregation_method='weighted')\nresult = check.run(train_dataset=train_dataset, test_dataset=test_dataset, model=model)\nresult.reduce_output()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}