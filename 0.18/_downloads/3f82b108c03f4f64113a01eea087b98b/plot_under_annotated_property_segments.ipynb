{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Under Annotated Property Segments {#nlp__under_annotated_property_segments}\n=================================\n\nThis notebook provides an overview for using and understanding the under\nannotated property segments check.\n\n**Structure:**\n\n-   [What is the purpose of the\n    check?](#what-is-the-purpose-of-the-check)\n-   [Automatically detecting under annotated\n    segments](#automatically-detecting-under-annotated-segments)\n-   [Generate data & model](#generate-data-model)\n-   [Run the check](#run-the-check)\n-   [Define a condition](#define-a-condition)\n\nWhat is the purpose of the check?\n---------------------------------\n\nThe Under-Annotated Property Segments check is designed to help you\neasily identify segments in your data which are under-annotated compared\nto the rest of your dataset, based on the provided\n`properties <nlp__properties_guide>`{.interpreted-text role=\"ref\"}. The\ncheck could be very useful in identifying a specific data samples (for\nexample less fluent or less formal samples) for which there was a\nproblem in the annotation process. The check can be guided to run only\non a specific list of properties, enabling you to focus on properties\nwhere you know an issue exists, or on important business segments.\n\nAutomatically detecting under annotated segments\n------------------------------------------------\n\nThe check contains two main steps:\n\n1.  We train multiple simple tree based models, each one is trained\n    using exactly two properties (out of the ones selected above) to\n    predict whether a sample will have a label.\n2.  We extract the corresponding data samples for each of the leaves in\n    each of the trees (data segments) and calculate the annotation ratio\n    in the samples within in. We keep the segments with the lowest\n    annotation ratio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate data & model\n=====================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.nlp.utils.test_utils import load_modified_tweet_text_data\n\ntext_data = load_modified_tweet_text_data()\ntext_data.properties.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the check\n=============\n\nThe check has several key parameters (that are all optional) that affect\nthe behavior of the check and especially its output.\n\n`properties / ignore_properties`: Controls which properties should be\nsearched for under annotated segments. By default, uses all properties.\n\n`segment_minimum_size_ratio`: Determines the minimum size of segments\nthat are of interest. The check will return data segments that contain\nat least this fraction of the total data samples. It is recommended to\ntry different configurations of this parameter as larger segments can be\nof interest even the model performance on them is superior.\n\n`categorical_aggregation_threshold`: By default the check will combine\nrare categories into a single category called \\\"Other\\\". This parameter\ndetermines the frequency threshold for categories to be mapped into to\nthe \\\"other\\\" category.\n\n`multiple_segments_per_column`: If True, will allow the same property to\nbe a segmenting feature in multiple segments, otherwise each property\ncan appear in one segment at most. False by default.\n\nsee\n`API reference <deepchecks.tabular.checks.model_evaluation.WeakSegmentsPerformance>`{.interpreted-text\nrole=\"class\"} for more details.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from deepchecks.nlp.checks import UnderAnnotatedPropertySegments\n\ncheck = UnderAnnotatedPropertySegments()\nresult = check.run(text_data)\nresult.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe the check\\'s output\n===========================\n\nWe see in the results that the check indeed found several under\nannotated segments. In the scatter plot display we can see the under\nannotated segment as well as the annotation distribution with respect to\nthe two properties that are relevant to the segment. In order to get the\nfull list of under annotated segments found we will inspect the\n`result.value` attribute. Shown below are the 3 segments with the worst\nperformance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result.value['weak_segments_list'].head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define a condition\n==================\n\nWe can add a condition that will validate the annotation ratio in all\ndata segment is above a certain threshold. A scenario where this can be\nuseful is when we want to make sure that we have enough annotations for\nquality evaluation of the model or drift on a subset of the data that is\nof interest to us, for example for specific age or gender groups.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Let's add a condition and re-run the check:\n\ncheck = UnderAnnotatedPropertySegments()\ncheck.add_condition_segments_annotation_ratio_greater_than(0.7)\nresult = check.run(text_data)\nresult.show(show_additional_outputs=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}